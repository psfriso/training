{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maintainable Code in Data Science\n",
    "\n",
    "This notebook should be used to test your implementation of the different functions provided in the exercise. If you're stuck, check the solution.\n",
    "\n",
    "Since you will be working in an IDE and importing your functions and classes in this notebook, we can use the `autoreload` magic method that automatically reloads your code when you modify it, so you do not have to restart the notebook everytime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the `load_dataset` function in your `model.py` should allow to load X and y (either train or test). The command below will load the training set. Check the folder `data` and the function `load_dataset` for more details.\n",
    "\n",
    "Here it is important to note that we have fixed `dtype` in `read_csv` to ensure whatever data we load, pandas will always try to load the columns with the same types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import load_dataset\n",
    "\n",
    "X_train, y_train = load_dataset(\"X_train.zip\", \"y_train.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Custom Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CategoriesExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will create a new transformer that allows to extra categories from the `category` column that is stored as a json. We want this transformer to have a parameter `use_all` that allows us to choose between filtering to use only a subset of hardcoded categories we care about or get all categories found in the json.\n",
    "\n",
    "The `transform` method should return two new columns, `gen_cat` the generic categorie, and `precise_cat` the precise category, those are extracted by assuming the json contains a string in the format `gen_cat/precise_cat`. We provide the method `extract_slug` that gets the two categories, and filter if necessary, so you only have to implement `fit` and `transform` to return the two new columns we want.\n",
    "\n",
    "If your transformer is correctly implemented, the code below should return the correct new columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CategoriesExtractor\n",
    "\n",
    "ce = CategoriesExtractor(use_all=False)\n",
    "ce.fit(X_train)\n",
    "ce.transform(X_train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GoalAdjustor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we want to build a simple transformer that returns a column `adjusted_goal` which is the goal multiplied by the static_USD_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GoalAdjustor\n",
    "\n",
    "ga = GoalAdjustor()\n",
    "ga.fit_transform(X_train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TimeTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we want to build a transformer that returns two columns: \n",
    "- `launched_to_deadline`: the number of days between launching day and the deadline\n",
    "- `created_to_launched`: the number of days between the creation of the page and the launch\n",
    "\n",
    "Note: to load the timestamp into datetime object you can multiply the timestamp by the constant `adj` defined in the class and then use the to_datetime function from pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TimeTransformer\n",
    "\n",
    "tt = TimeTransformer()\n",
    "tt.fit_transform(X_train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountryTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This transformer returns a larger area for the country feature, allowing to have less dummy features later. We provide a dictionary of countries and their corresponding groups, but feel free to change those depending on similarities you see between countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CountryTransformer\n",
    "\n",
    "ct = CountryTransformer()\n",
    "ct.fit_transform(X_train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Column Transformer and Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will implement the `build_model` function that is defined in `model.py`. This function should return a new Pipeline object that has two stages:\n",
    "- `preprocessor`: A ColumnTransformer object that has all your preprocessing steps\n",
    "- `model`: A predictive model, here we will use the `DecisionTreeClassifier`\n",
    "\n",
    "We are providing code to build two simple intermediary Pipeline objects: `cat_processor` and `country_processor`. Those are just combining our `CategoriesExtractor` and `CountryTransformer` with a `OneHotEncoder` stage so the output is an array of 1 and 0 for all.\n",
    "\n",
    "You only have to implement: \n",
    "- the main ColumnTransformer that puts all the transformers together and applies them on the right columns\n",
    "- the final Pipeline object that puts together the preprocessor and model.\n",
    "\n",
    "The code below will get a new model using your function, train it on the data and generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import build_model\n",
    "\n",
    "model = build_model()\n",
    "model.fit(X_train, y_train)\n",
    "model.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: tuning, training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, implement `tune_model` that loads the data (we have a function to do that already), instanciate a model (we have a function for it), runs a gridsearch on it (load `GRID_PARAMS` from `config.py` to use in the grid search).\n",
    "\n",
    "It should then print out the best score and hyperparameters found. \n",
    "\n",
    "The code below should run your tuning function and print the best parameters. Before running it, make sure you define some parameters to tune in `GRID_PARAMS`, those have to match the pipeline format, you can get a list of all parameters' names in your model by doing `model.get_params().keys()`\n",
    "\n",
    "\n",
    "Node: Depending on your use case you might prefer to return the values instead of printing them, but here to keep things simple we will assume that the user then modifies the config manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import tune_model\n",
    "\n",
    "tune_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training, implement `train_model` that loads data and model, uses `set_params` to set the parameters of the model to those defined in `PARAMS` inside `config.py` (make sure you use `**PARAMS` in set_params so it unpacks the dictionary).\n",
    "\n",
    "It should then train the model and use `joblib` to save it as a file. The file should be name after the variable `MODEL_NAME`, again defined in config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import train_model\n",
    "\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this properly saved a model, the code below should load it and generate predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "model_loaded = joblib.load(\"model.joblib\")\n",
    "model_loaded.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing, we will need to load the test dataset, the model that we have saved in joblib format (dont instanciate a new model), generate prediction and print metrics such as accuracy score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import test_model\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now that you have implemented everything, you can use the `run.py` script to work with your model on the command line:\n",
    "\n",
    "- `python run.py tune`: will tune your model\n",
    "- `python run.py train`: will train it\n",
    "- `python run.py test`: will test it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
