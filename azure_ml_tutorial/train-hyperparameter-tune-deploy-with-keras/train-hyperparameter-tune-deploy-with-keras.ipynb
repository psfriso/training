{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/training-with-deep-learning/train-hyperparameter-tune-deploy-with-keras/train-hyperparameter-tune-deploy-with-keras.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "bf74d2e9-2708-49b1-934b-e0ede342f475"
    }
   },
   "source": [
    "# Training, hyperparameter tune, and deploy with Keras\n",
    "\n",
    "## Introduction\n",
    "This tutorial shows how to train a simple deep neural network using the MNIST dataset and Keras on Azure Machine Learning. MNIST is a popular dataset consisting of 70,000 grayscale images. Each image is a handwritten digit of `28x28` pixels, representing number from 0 to 9. The goal is to create a multi-class classifier to identify the digit each image represents, and deploy it as a web service in Azure.\n",
    "\n",
    "For more information about the MNIST dataset, please visit [Yan LeCun's website](http://yann.lecun.com/exdb/mnist/).\n",
    "\n",
    "## Prerequisite:\n",
    "* Understand the [architecture and terms](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture) introduced by Azure Machine Learning\n",
    "* If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, go through the [configuration notebook](../../../configuration.ipynb) to:\n",
    "    * install the AML SDK\n",
    "    * create a workspace and its configuration file (`config.json`)\n",
    "* For local scoring test, you will also need to have `tensorflow` and `keras` installed in the current Jupyter kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started. First let's import some Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "c377ea0c-0cd9-4345-9be2-e20fb29c94c3"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "edaa7f2f-2439-4148-b57a-8c794c0945ec"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.0.43\n"
     ]
    }
   ],
   "source": [
    "import azureml\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize workspace\n",
    "Initialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object from the existing workspace you created in the Prerequisites step. `Workspace.from_config()` creates a workspace object from the details stored in `config.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: azure-ml-experiments\n",
      "Azure region: northeurope\n",
      "Subscription id: 79ec9c01-599f-4707-82f9-31b2d938f2e5\n",
      "Resource group: pedro-test\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "59f52294-4a25-4c92-bab8-3b07f0f44d15"
    }
   },
   "source": [
    "## Create an Azure ML experiment\n",
    "Let's create an experiment named \"keras-mnist\" and a folder to hold the training scripts. The script runs will be recorded under the experiment in Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbpresent": {
     "id": "bc70f780-c240-4779-96f3-bc5ef9a37d59"
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "script_folder = './keras-mnist'\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "\n",
    "exp = Experiment(workspace=ws, name='keras-mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that the datasource in in there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or Attach existing AmlCompute\n",
    "You will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) for training your model. In this tutorial, you create `AmlCompute` as your training compute resource."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we could not find the cluster with the given name, then we will create a new cluster here. We will create an `AmlCompute` cluster of `STANDARD_NC6` GPU VMs. This process is broken down into 3 steps:\n",
    "1. create the configuration (this step is local and only takes a second)\n",
    "2. create the cluster (this step will take about **20 seconds**)\n",
    "3. provision the VMs to bring the cluster to the initial size (of 1 in this case). This step will take about **3-5 minutes** and is providing only sparse output in the process. Please make sure to wait until the call returns before moving to the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target\n",
      "{'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2019-06-24T15:54:07.616000+00:00', 'errors': None, 'creationTime': '2019-06-24T15:53:20.147297+00:00', 'modifiedTime': '2019-06-24T15:54:12.544682+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 2, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"gpu-cluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6', \n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it uses the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have created the compute target, let's see what the workspace's `compute_targets` property returns. You should now see one entry named \"gpu-cluster\" of type `AmlCompute`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu-cluster AmlCompute Succeeded\n",
      "gpu-cluster AmlCompute Succeeded\n",
      "azure-ml-cpu AmlCompute Succeeded\n"
     ]
    }
   ],
   "source": [
    "compute_targets = ws.compute_targets\n",
    "for name, ct in compute_targets.items():\n",
    "    print(name, ct.type, ct.provisioning_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy the training files into the script folder\n",
    "The Keras training script is already created for you. You can simply copy it into the script folder, together with the utility library used to load compressed data file into numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./keras-mnist/utils.py'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# the training logic is in the keras_mnist.py file.\n",
    "shutil.copy('./keras_mnist.py', script_folder)\n",
    "\n",
    "# the utils.py just helps loading data from the downloaded MNIST dataset into numpy arrays.\n",
    "shutil.copy('./utils.py', script_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "2039d2d5-aca6-4f25-a12f-df9ae6529cae"
    }
   },
   "source": [
    "## Construct neural network in Keras\n",
    "In the training script `keras_mnist.py`, it creates a very simple DNN (deep neural network), with just 2 hidden layers. The input layer has 28 * 28 = 784 neurons, each representing a pixel in an image. The first hidden layer has 300 neurons, and the second hidden layer has 100 neurons. The output layer has 10 neurons, each representing a targeted label from 0 to 9.\n",
    "\n",
    "![DNN](nn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure ML concepts  \n",
    "Please note the following three things in the code below:\n",
    "1. The script accepts arguments using the argparse package. In this case there is one argument `--data_folder` which specifies the file system folder in which the script can find the MNIST data\n",
    "```\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--data_folder')\n",
    "```\n",
    "2. The script is accessing the Azure ML `Run` object by executing `run = Run.get_context()`. Further down the script is using the `run` to report the loss and accuracy at the end of each epoch via callback.\n",
    "```\n",
    "    run.log('Loss', log['loss'])\n",
    "    run.log('Accuracy', log['acc'])\n",
    "```\n",
    "3. When running the script on Azure ML, you can write files out to a folder `./outputs` that is relative to the root directory. This folder is specially tracked by Azure ML in the sense that any files written to that folder during script execution on the remote target will be picked up by Run History; these files (known as artifacts) will be available as part of the run history record."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell will print out the training code for you to inspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
      "# Licensed under the MIT License.\n",
      "\n",
      "import numpy as np\n",
      "import argparse\n",
      "import os\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import keras\n",
      "from keras.models import Sequential, model_from_json\n",
      "from keras.layers import Dense\n",
      "from keras.optimizers import RMSprop\n",
      "from keras.callbacks import Callback\n",
      "\n",
      "import tensorflow as tf\n",
      "\n",
      "from azureml.core import Run\n",
      "from utils import load_data, one_hot_encode\n",
      "\n",
      "print(\"Keras version:\", keras.__version__)\n",
      "print(\"Tensorflow version:\", tf.__version__)\n",
      "\n",
      "parser = argparse.ArgumentParser()\n",
      "parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder mounting point')\n",
      "parser.add_argument('--batch-size', type=int, dest='batch_size', default=50, help='mini batch size for training')\n",
      "parser.add_argument('--first-layer-neurons', type=int, dest='n_hidden_1', default=100,\n",
      "                    help='# of neurons in the first layer')\n",
      "parser.add_argument('--second-layer-neurons', type=int, dest='n_hidden_2', default=100,\n",
      "                    help='# of neurons in the second layer')\n",
      "parser.add_argument('--learning-rate', type=float, dest='learning_rate', default=0.001, help='learning rate')\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "data_folder = args.data_folder\n",
      "\n",
      "print('training dataset is stored here:', data_folder)\n",
      "\n",
      "X_train = load_data(os.path.join(data_folder, 'train-images.gz'), False) / 255.0\n",
      "X_test = load_data(os.path.join(data_folder, 'test-images.gz'), False) / 255.0\n",
      "\n",
      "y_train = load_data(os.path.join(data_folder, 'train-labels.gz'), True).reshape(-1)\n",
      "y_test = load_data(os.path.join(data_folder, 'test-labels.gz'), True).reshape(-1)\n",
      "\n",
      "training_set_size = X_train.shape[0]\n",
      "\n",
      "n_inputs = 28 * 28\n",
      "n_h1 = args.n_hidden_1\n",
      "n_h2 = args.n_hidden_2\n",
      "n_outputs = 10\n",
      "n_epochs = 20\n",
      "batch_size = args.batch_size\n",
      "learning_rate = args.learning_rate\n",
      "\n",
      "y_train = one_hot_encode(y_train, n_outputs)\n",
      "y_test = one_hot_encode(y_test, n_outputs)\n",
      "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, sep='\\n')\n",
      "\n",
      "# Build a simple MLP model\n",
      "model = Sequential()\n",
      "# first hidden layer\n",
      "model.add(Dense(n_h1, activation='relu', input_shape=(n_inputs,)))\n",
      "# second hidden layer\n",
      "model.add(Dense(n_h2, activation='relu'))\n",
      "# output layer\n",
      "model.add(Dense(n_outputs, activation='softmax'))\n",
      "\n",
      "model.summary()\n",
      "\n",
      "model.compile(loss='categorical_crossentropy',\n",
      "              optimizer=RMSprop(lr=learning_rate),\n",
      "              metrics=['accuracy'])\n",
      "\n",
      "# start an Azure ML run\n",
      "run = Run.get_context()\n",
      "\n",
      "\n",
      "class LogRunMetrics(Callback):\n",
      "    # callback at the end of every epoch\n",
      "    def on_epoch_end(self, epoch, log):\n",
      "        # log a value repeated which creates a list\n",
      "        run.log('Loss', log['loss'])\n",
      "        run.log('Accuracy', log['acc'])\n",
      "\n",
      "\n",
      "history = model.fit(X_train, y_train,\n",
      "                    batch_size=batch_size,\n",
      "                    epochs=n_epochs,\n",
      "                    verbose=2,\n",
      "                    validation_data=(X_test, y_test),\n",
      "                    callbacks=[LogRunMetrics()])\n",
      "\n",
      "score = model.evaluate(X_test, y_test, verbose=0)\n",
      "\n",
      "# log a single value\n",
      "run.log(\"Final test loss\", score[0])\n",
      "print('Test loss:', score[0])\n",
      "\n",
      "run.log('Final test accuracy', score[1])\n",
      "print('Test accuracy:', score[1])\n",
      "\n",
      "plt.figure(figsize=(6, 3))\n",
      "plt.title('MNIST with Keras MLP ({} epochs)'.format(n_epochs), fontsize=14)\n",
      "plt.plot(history.history['acc'], 'b-', label='Accuracy', lw=4, alpha=0.5)\n",
      "plt.plot(history.history['loss'], 'r--', label='Loss', lw=4, alpha=0.5)\n",
      "plt.legend(fontsize=12)\n",
      "plt.grid(True)\n",
      "\n",
      "# log an image\n",
      "run.log_image('Accuracy vs Loss', plot=plt)\n",
      "\n",
      "# create a ./outputs/model folder in the compute target\n",
      "# files saved in the \"./outputs\" folder are automatically uploaded into run history\n",
      "os.makedirs('./outputs/model', exist_ok=True)\n",
      "\n",
      "# serialize NN architecture to JSON\n",
      "model_json = model.to_json()\n",
      "# save model JSON\n",
      "with open('./outputs/model/model.json', 'w') as f:\n",
      "    f.write(model_json)\n",
      "# save model weights\n",
      "model.save_weights('./outputs/model/model.h5')\n",
      "print(\"model saved in ./outputs/model folder\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(script_folder, './keras_mnist.py'), 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TensorFlow estimator & add Keras\n",
    "Next, we construct an `azureml.train.dnn.TensorFlow` estimator object, use the `gpu-cluster` as compute target, and pass the mount-point of the datastore to the training code as a parameter.\n",
    "The TensorFlow estimator is providing a simple way of launching a TensorFlow training job on a compute target. It will automatically provide a docker image that has TensorFlow installed. In this case, we add `keras` package (for the Keras framework obviously), and `matplotlib` package for plotting a \"Loss vs. Accuracy\" chart and record it in run history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - framework_version is not specified, defaulting to version 1.13.\n"
     ]
    }
   ],
   "source": [
    "from azureml.train.dnn import TensorFlow\n",
    "\n",
    "script_params = {\n",
    "    '--data-folder': ds.path('mnist').as_mount(),\n",
    "    '--batch-size': 50,\n",
    "    '--first-layer-neurons': 300,\n",
    "    '--second-layer-neurons': 100,\n",
    "    '--learning-rate': 0.001\n",
    "}\n",
    "\n",
    "est = TensorFlow(source_directory=script_folder,\n",
    "                 script_params=script_params,\n",
    "                 compute_target=compute_target, \n",
    "                 pip_packages=['keras', 'matplotlib'],\n",
    "                 entry_script='keras_mnist.py', \n",
    "                 use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if you are curious, this is what the mounting point looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$AZUREML_DATAREFERENCE_f8f3e69ca84544d39b2d30263523ce37\n"
     ]
    }
   ],
   "source": [
    "print(ds.path('mnist').as_mount())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit job to run\n",
    "Submit the estimator to the Azure ML experiment to kick off the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = exp.submit(est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor the Run\n",
    "As the Run is executed, it will go through the following stages:\n",
    "1. Preparing: A docker image is created matching the Python environment specified by the TensorFlow estimator and it will be uploaded to the workspace's Azure Container Registry. This step will only happen once for each Python environment -- the container will then be cached for subsequent runs. Creating and uploading the image takes about **5 minutes**. While the job is preparing, logs are streamed to the run history and can be viewed to monitor the progress of the image creation.\n",
    "\n",
    "2. Scaling: If the compute needs to be scaled up (i.e. the AmlCompute cluster requires more nodes to execute the run than currently available), the cluster will attempt to scale up in order to make the required amount of nodes available. Scaling typically takes about **5 minutes**.\n",
    "\n",
    "3. Running: All scripts in the script folder are uploaded to the compute target, data stores are mounted/copied and the `entry_script` is executed. While the job is running, stdout and the `./logs` folder are streamed to the run history and can be viewed to monitor the progress of the run.\n",
    "\n",
    "4. Post-Processing: The `./outputs` folder of the run is copied over to the run history\n",
    "\n",
    "There are multiple ways to check the progress of a running job. We can use a Jupyter notebook widget. \n",
    "\n",
    "**Note: The widget will automatically update ever 10-15 seconds, always showing you the most up-to-date information about the run**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The widget isn't working**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also periodically check the status of the run object, and navigate to Azure portal to monitor the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>keras-mnist</td><td>keras-mnist_1561473949_451ed77e</td><td>azureml.scriptrun</td><td>Preparing</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/79ec9c01-599f-4707-82f9-31b2d938f2e5/resourceGroups/pedro-test/providers/Microsoft.MachineLearningServices/workspaces/azure-ml-experiments/experiments/keras-mnist/runs/keras-mnist_1561473949_451ed77e\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: keras-mnist,\n",
       "Id: keras-mnist_1561473949_451ed77e,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Preparing)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: keras-mnist_1561473949_451ed77e\n",
      "Web View: https://mlworkspace.azure.ai/portal/subscriptions/79ec9c01-599f-4707-82f9-31b2d938f2e5/resourceGroups/pedro-test/providers/Microsoft.MachineLearningServices/workspaces/azure-ml-experiments/experiments/keras-mnist/runs/keras-mnist_1561473949_451ed77e\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "\n",
      "2019/06/25 14:45:58 Downloading source code...\n",
      "2019/06/25 14:45:59 Finished downloading source code\n",
      "2019/06/25 14:46:00 Using acb_vol_083f6e5b-0b61-4566-b482-c805f4ef33f1 as the home volume\n",
      "2019/06/25 14:46:00 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2019/06/25 14:46:00 Successfully set up Docker network: acb_default_network\n",
      "2019/06/25 14:46:00 Setting up Docker configuration...\n",
      "2019/06/25 14:46:01 Successfully set up Docker configuration\n",
      "2019/06/25 14:46:01 Logging in to registry: azuremlexperd4996c19.azurecr.io\n",
      "2019/06/25 14:46:02 Successfully logged into azuremlexperd4996c19.azurecr.io\n",
      "2019/06/25 14:46:02 Executing step ID: acb_step_0. Timeout(sec): 1800, Working directory: '', Network: 'acb_default_network'\n",
      "2019/06/25 14:46:02 Scanning for dependencies...\n",
      "2019/06/25 14:46:02 Successfully scanned dependencies\n",
      "2019/06/25 14:46:02 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon  46.59kB\n",
      "\n",
      "Step 1/14 : FROM mcr.microsoft.com/azureml/base-gpu:intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04@sha256:a36e319c7539a8e19c42b4c010da91e8fe776158b428b2f6facdf14c0469b6d3\n",
      "sha256:a36e319c7539a8e19c42b4c010da91e8fe776158b428b2f6facdf14c0469b6d3: Pulling from azureml/base-gpu\n",
      "34667c7e4631: Pulling fs layer\n",
      "d18d76a881a4: Pulling fs layer\n",
      "119c7358fbfc: Pulling fs layer\n",
      "2aaf13f3eff0: Pulling fs layer\n",
      "28d5148dfcec: Pulling fs layer\n",
      "454bc542fc4c: Pulling fs layer\n",
      "369f77cbea49: Pulling fs layer\n",
      "ac4ef821cc62: Pulling fs layer\n",
      "9b9781a46f34: Pulling fs layer\n",
      "ade089defcf2: Pulling fs layer\n",
      "423c349d3c85: Pulling fs layer\n",
      "32b351e04ea6: Pulling fs layer\n",
      "7b5f45e8466e: Pulling fs layer\n",
      "78b2788127b6: Pulling fs layer\n",
      "d3c0d8d71db8: Pulling fs layer\n",
      "2aaf13f3eff0: Waiting\n",
      "28d5148dfcec: Waiting\n",
      "454bc542fc4c: Waiting\n",
      "369f77cbea49: Waiting\n",
      "ac4ef821cc62: Waiting\n",
      "9b9781a46f34: Waiting\n",
      "ade089defcf2: Waiting\n",
      "423c349d3c85: Waiting\n",
      "32b351e04ea6: Waiting\n",
      "7b5f45e8466e: Waiting\n",
      "78b2788127b6: Waiting\n",
      "d3c0d8d71db8: Waiting\n",
      "119c7358fbfc: Verifying Checksum\n",
      "119c7358fbfc: Download complete\n",
      "d18d76a881a4: Verifying Checksum\n",
      "d18d76a881a4: Download complete\n",
      "2aaf13f3eff0: Verifying Checksum\n",
      "2aaf13f3eff0: Download complete\n",
      "454bc542fc4c: Verifying Checksum\n",
      "454bc542fc4c: Download complete\n",
      "369f77cbea49: Verifying Checksum\n",
      "369f77cbea49: Download complete\n",
      "28d5148dfcec: Verifying Checksum\n",
      "28d5148dfcec: Download complete\n",
      "34667c7e4631: Verifying Checksum\n",
      "34667c7e4631: Download complete\n",
      "ade089defcf2: Verifying Checksum\n",
      "ade089defcf2: Download complete\n",
      "9b9781a46f34: Verifying Checksum\n",
      "9b9781a46f34: Download complete\n",
      "ac4ef821cc62: Verifying Checksum\n",
      "ac4ef821cc62: Download complete\n",
      "423c349d3c85: Verifying Checksum\n",
      "423c349d3c85: Download complete\n",
      "78b2788127b6: Verifying Checksum\n",
      "78b2788127b6: Download complete\n",
      "d3c0d8d71db8: Verifying Checksum\n",
      "d3c0d8d71db8: Download complete\n",
      "32b351e04ea6: Verifying Checksum\n",
      "32b351e04ea6: Download complete\n",
      "7b5f45e8466e: Verifying Checksum\n",
      "7b5f45e8466e: Download complete\n",
      "34667c7e4631: Pull complete\n",
      "d18d76a881a4: Pull complete\n",
      "119c7358fbfc: Pull complete\n",
      "2aaf13f3eff0: Pull complete\n",
      "28d5148dfcec: Pull complete\n",
      "454bc542fc4c: Pull complete\n",
      "369f77cbea49: Pull complete\n",
      "ac4ef821cc62: Pull complete\n",
      "9b9781a46f34: Pull complete\n",
      "ade089defcf2: Pull complete\n",
      "423c349d3c85: Pull complete\n",
      "32b351e04ea6: Pull complete\n",
      "7b5f45e8466e: Pull complete\n",
      "78b2788127b6: Pull complete\n",
      "d3c0d8d71db8: Pull complete\n",
      "Digest: sha256:a36e319c7539a8e19c42b4c010da91e8fe776158b428b2f6facdf14c0469b6d3\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/base-gpu:intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04@sha256:a36e319c7539a8e19c42b4c010da91e8fe776158b428b2f6facdf14c0469b6d3\n",
      " ---> 7c7fb3ba4ec9\n",
      "Step 2/14 : USER root\n",
      " ---> Running in 1fb0f5ea41a5\n",
      "Removing intermediate container 1fb0f5ea41a5\n",
      " ---> f0f5c3f0ed24\n",
      "Step 3/14 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in 5aba0cd2c6f1\n",
      "Removing intermediate container 5aba0cd2c6f1\n",
      " ---> 1317ac8d0fbe\n",
      "Step 4/14 : WORKDIR /\n",
      " ---> Running in 0455d51b842a\n",
      "Removing intermediate container 0455d51b842a\n",
      " ---> ad370129042a\n",
      "Step 5/14 : COPY azureml-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> 2bfa96121776\n",
      "Step 6/14 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      " ---> Running in 0b01e2545791\n",
      "Removing intermediate container 0b01e2545791\n",
      " ---> 04fc1932ba97\n",
      "Step 7/14 : COPY azureml-setup/mutated_conda_dependencies.yml azureml-setup/mutated_conda_dependencies.yml\n",
      " ---> cb4444dbc43b\n",
      "Step 8/14 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_57642d55fb33a477d2549fe0ee5ff8fd -f azureml-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      " ---> Running in 70d23d2b1d15\n",
      "Solving environment: ...working... done\n",
      "\u001b[91m\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.5.11\n",
      "  latest version: 4.6.14\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "sqlite-3.13.0        | 4.9 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "sqlite-3.13.0        | 4.9 MB    | #######6   |  76% \u001b[0m\u001b[91m\n",
      "sqlite-3.13.0        | 4.9 MB    | #########8 |  99% \u001b[0m\u001b[91m\n",
      "sqlite-3.13.0        | 4.9 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "setuptools-41.0.1    | 612 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "setuptools-41.0.1    | 612 KB    | ########5  |  85% \u001b[0m\u001b[91m\n",
      "setuptools-41.0.1    | 612 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "ca-certificates-2019 | 145 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "ca-certificates-2019 | 145 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "pip-19.1.1           | 1.8 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "pip-19.1.1           | 1.8 MB    | #######8   |  79% \u001b[0m\u001b[91m\n",
      "pip-19.1.1           | 1.8 MB    | #########5 |  96% \u001b[0m\u001b[91m\n",
      "pip-19.1.1           | 1.8 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "python-3.6.2         | 19.0 MB   |            |   0% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 19.0 MB   | ##4        |  25% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 19.0 MB   | ######     |  60% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 19.0 MB   | #######6   |  76% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 19.0 MB   | ########8  |  88% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 19.0 MB   | #########6 |  97% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 19.0 MB   | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "certifi-2019.6.16    | 148 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "certifi-2019.6.16    | 148 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libgcc-ng-9.1.0      | 8.1 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "libgcc-ng-9.1.0      | 8.1 MB    | #######5   |  75% \u001b[0m\u001b[91m\n",
      "libgcc-ng-9.1.0      | 8.1 MB    | #########7 |  98% \u001b[0m\u001b[91m\n",
      "libgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "ncurses-5.9          | 1.1 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "ncurses-5.9          | 1.1 MB    | #######8   |  79% \u001b[0m\u001b[91m\n",
      "ncurses-5.9          | 1.1 MB    | ########8  |  89% \u001b[0m\u001b[91m\n",
      "ncurses-5.9          | 1.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "readline-6.2         | 713 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "readline-6.2         | 713 KB    | #########3 |  94% \u001b[0m\u001b[91m\n",
      "readline-6.2         | 713 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "xz-5.2.4             | 366 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "xz-5.2.4             | 366 KB    | #########9 | 100% \u001b[0m\u001b[91m\n",
      "xz-5.2.4             | 366 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "wheel-0.33.4         | 34 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "wheel-0.33.4         | 34 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "tk-8.5.19            | 1.9 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "tk-8.5.19            | 1.9 MB    | #######7   |  78% \u001b[0m\u001b[91m\n",
      "tk-8.5.19            | 1.9 MB    | #########1 |  92% \u001b[0m\u001b[91m\n",
      "tk-8.5.19            | 1.9 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "zlib-1.2.11          | 101 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "zlib-1.2.11          | 101 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "openssl-1.0.2r       | 3.1 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2r       | 3.1 MB    | #######7   |  78% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2r       | 3.1 MB    | ########## | 100% \u001b[0m\n",
      "Downloading and Extracting Packages\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Collecting keras (from -r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
      "Collecting matplotlib (from -r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/da/83/d989ee20c78117c737ab40e0318ea221f1aed4e3f5a40b4f93541b369b93/matplotlib-3.1.0-cp36-cp36m-manylinux1_x86_64.whl (13.1MB)\n",
      "Collecting azureml-defaults (from -r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading https://files.pythonhosted.org/packages/2c/f4/c34cb32d3c789e5205d9bc1a9b7f191f3dfe45a9fab5655d7441c198f63b/azureml_defaults-1.0.43-py2.py3-none-any.whl\n",
      "Collecting tensorflow-gpu==1.13.1 (from -r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/b1/0ad4ae02e17ddd62109cd54c291e311c4b5fd09b4d0678d3d6ce4159b0f0/tensorflow_gpu-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (345.2MB)\n",
      "Collecting horovod==0.16.1 (from -r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/89/70/327e1ce9bee0fb8a879b98f8265fb7a41ae6d04a3ee019b2bafba8b66333/horovod-0.16.1.tar.gz (2.6MB)\n",
      "Collecting pyyaml (from keras->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/65/837fefac7475963d1eccf4aa684c23b95aa6c1d033a2c5965ccb11e22623/PyYAML-5.1.1.tar.gz (274kB)\n",
      "Collecting keras-preprocessing>=1.0.5 (from keras->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "Collecting numpy>=1.9.1 (from keras->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/87/2d/e4656149cbadd3a8a0369fcd1a9c7d61cc7b87b3903b85389c70c989a696/numpy-1.16.4-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
      "Collecting six>=1.9.0 (from keras->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
      "Collecting keras-applications>=1.0.6 (from keras->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "Collecting h5py (from keras->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/30/99/d7d4fbf2d02bb30fb76179911a250074b55b852d34e98dd452a9f394ac06/h5py-2.9.0-cp36-cp36m-manylinux1_x86_64.whl (2.8MB)\n",
      "Collecting scipy>=0.14 (from keras->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/72/4c/5f81e7264b0a7a8bd570810f48cd346ba36faedbd2ba255c873ad556de76/scipy-1.3.0-cp36-cp36m-manylinux1_x86_64.whl (25.2MB)\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/f8/a1/5742b56282449b1c0968197f63eae486eca2c35dcd334bab75ad524e0de1/kiwisolver-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (90kB)\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/dd/d9/3ec19e966301a6e25769976999bd7bbe552016f0d32b577dc9d63d2e0c49/pyparsing-2.4.0-py2.py3-none-any.whl (62kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Collecting python-dateutil>=2.1 (from matplotlib->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n",
      "Collecting applicationinsights>=0.11.7 (from azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/a1/53/234c53004f71f0717d8acd37876e0b65c121181167057b9ce1b1795f96a0/applicationinsights-0.11.9-py2.py3-none-any.whl (58kB)\n",
      "Collecting azureml-core==1.0.43.* (from azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/f6/b2/ba8fde6c28251cec7fee4f6040ba13476a42ecbc138785bf958a5f500704/azureml_core-1.0.43.1-py2.py3-none-any.whl (937kB)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-gpu==1.13.1->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting protobuf>=3.6.1 (from tensorflow-gpu==1.13.1->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/d2/fb/29de8d08967f0cce1bb10b39846d836b0f3bf6776ddc36aed7c73498ca7e/protobuf-3.8.0-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n",
      "Collecting astor>=0.6.0 (from tensorflow-gpu==1.13.1->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: wheel>=0.26 in /azureml-envs/azureml_57642d55fb33a477d2549fe0ee5ff8fd/lib/python3.6/site-packages (from tensorflow-gpu==1.13.1->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 4)) (0.33.4)\n",
      "Collecting tensorboard<1.14.0,>=1.13.0 (from tensorflow-gpu==1.13.1->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
      "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0 (from tensorflow-gpu==1.13.1->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
      "Collecting grpcio>=1.8.6 (from tensorflow-gpu==1.13.1->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/99/83/18f374294bf34128a448ee2fae37651f943b0b5fa473b5b3aff262c15bf8/grpcio-1.21.1-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
      "Collecting absl-py>=0.1.6 (from tensorflow-gpu==1.13.1->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/da/3f/9b0355080b81b15ba6a9ffcf1f5ea39e307a2778b2f2dc8694724e8abd5b/absl-py-0.7.1.tar.gz (99kB)\n",
      "Collecting gast>=0.2.0 (from tensorflow-gpu==1.13.1->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Collecting cffi>=1.4.0 (from horovod==0.16.1->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/5f/bf/6aa1925384c23ffeb579e97a5569eb9abce41b6310b329352b8252cee1c3/cffi-1.12.3-cp36-cp36m-manylinux1_x86_64.whl (430kB)\n",
      "Collecting cloudpickle (from horovod==0.16.1->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/09/f4/4a080c349c1680a2086196fcf0286a65931708156f39568ed7051e42ff6a/cloudpickle-1.2.1-py2.py3-none-any.whl\n",
      "Collecting psutil (from horovod==0.16.1->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/1c/ca/5b8c1fe032a458c2c4bcbe509d1401dca9dda35c7fc46b36bb81c2834740/psutil-5.6.3.tar.gz (435kB)\n",
      "Requirement already satisfied: setuptools in /azureml-envs/azureml_57642d55fb33a477d2549fe0ee5ff8fd/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 2)) (41.0.1)\n",
      "Collecting pytz (from azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/3d/73/fe30c2daaaa0713420d0382b16fbb761409f532c56bdcc514bf7b6262bb6/pytz-2019.1-py2.py3-none-any.whl (510kB)\n",
      "Collecting requests>=2.19.1 (from azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
      "Collecting SecretStorage (from azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/82/59/cb226752e20d83598d7fdcabd7819570b0329a61db07cfbdd21b2ef546e3/SecretStorage-3.1.1-py3-none-any.whl\n",
      "Collecting azure-mgmt-storage>=1.5.0 (from azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/8c/03/62c3ed229b9b83fbf4dcd56ae27d5d835f3bd921004c09a478729c221fff/azure_mgmt_storage-4.0.0-py2.py3-none-any.whl (426kB)\n",
      "Collecting pathspec (from azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/84/2a/bfee636b1e2f7d6e30dd74f49201ccfa5c3cf322d44929ecc6c137c486c5/pathspec-0.5.9.tar.gz\n",
      "Collecting azure-graphrbac>=0.40.0 (from azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/3e/93/02056aca45162f9fc275d1eaad12a2a07ef92375afb48eabddc4134b8315/azure_graphrbac-0.61.1-py2.py3-none-any.whl (141kB)\n",
      "Collecting msrest>=0.5.1 (from azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/56/1d/a5947aba03169aeccd2d6539a3986614d133be53adac028ec3d6a1a285a4/msrest-0.6.8-py2.py3-none-any.whl (82kB)\n",
      "Collecting docker (from azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/95/47/5560c9cf0c92b50da24216f0e7733250fbed5a497f69e3c70e1be62143fe/docker-4.0.2-py2.py3-none-any.whl (138kB)\n",
      "Collecting azure-mgmt-keyvault>=0.40.0 (from azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/b3/d1/9fed0a3a3b43d0b1ad59599b5c836ccc4cf117e26458075385bafe79575b/azure_mgmt_keyvault-2.0.0-py2.py3-none-any.whl (80kB)\n",
      "Collecting jsonpickle (from azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/07/07/c157520a3ebd166c8c24c6ae0ecae7c3968eb4653ff0e5af369bb82f004d/jsonpickle-1.2-py2.py3-none-any.whl\n",
      "Collecting backports.tempfile (from azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/b4/5c/077f910632476281428fe254807952eb47ca78e720d059a46178c541e669/backports.tempfile-1.0-py2.py3-none-any.whl\n",
      "Collecting contextlib2 (from azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/a2/71/8273a7eeed0aff6a854237ab5453bc9aa67deb49df4832801c21f0ff3782/contextlib2-0.5.5-py2.py3-none-any.whl\n",
      "Collecting adal>=1.2.0 (from azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/00/72/53dce9e4f5d6c1aa57b8d408cb34dff1969ecbf10ab7e678f32c5e0e2397/adal-1.2.1-py2.py3-none-any.whl (52kB)\n",
      "Collecting pyopenssl (from azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/01/c8/ceb170d81bd3941cbeb9940fc6cc2ef2ca4288d0ca8929ea4db5905d904d/pyOpenSSL-19.0.0-py2.py3-none-any.whl (53kB)\n",
      "Collecting msrestazure>=0.4.33 (from azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/0a/aa/b17a4f702ecd6d9e989ae34109aa384c988aed0de37215c651165ed45238/msrestazure-0.6.1-py2.py3-none-any.whl (40kB)\n",
      "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.* (from azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/97/18/c6557f63a6abde34707196fb2cad1c6dc0dbff25a200d5044922496668a4/cryptography-2.7-cp34-abi3-manylinux1_x86_64.whl (2.3MB)\n",
      "Collecting azure-common>=1.1.12 (from azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/00/55/a703923c12cd3172d5c007beda0c1a34342a17a6a72779f8a7c269af0cd6/azure_common-1.1.23-py2.py3-none-any.whl\n",
      "Collecting urllib3>=1.23 (from azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/e6/60/247f23a7121ae632d62811ba7f273d0e58972d75e58a94d329d51550a47d/urllib3-1.25.3-py2.py3-none-any.whl (150kB)\n",
      "Collecting azure-mgmt-containerregistry>=2.0.0 (from azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/97/70/8c2d0509db466678eba16fa2b0a539499f3b351b1f2993126ad843d5be13/azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718kB)\n",
      "Collecting ndg-httpsclient (from azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/fb/67/c2f508c00ed2a6911541494504b7cac16fe0b0473912568df65fd1801132/ndg_httpsclient-0.5.1-py3-none-any.whl\n",
      "Collecting jmespath (from azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/83/94/7179c3832a6d45b266ddb2aac329e101367fbdb11f425f13771d27f225bb/jmespath-0.9.4-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-authorization>=0.40.0 (from azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/6b/b2/c0d62a3a91c13641e09af294c13fe16929f88dc5902718388cd9b292217f/azure_mgmt_authorization-0.52.0-py2.py3-none-any.whl (112kB)\n",
      "Collecting ruamel.yaml<=0.15.89,>=0.15.35 (from azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/36/e1/cc2fa400fa5ffde3efa834ceb15c464075586de05ca3c553753dcd6f1d3b/ruamel.yaml-0.15.89-cp36-cp36m-manylinux1_x86_64.whl (651kB)\n",
      "Collecting azure-mgmt-resource>=1.2.1 (from azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/97/1e/03813b5705b46d86d8d6d594930b78f14b13d901b5ca089152e06e67b680/azure_mgmt_resource-3.0.0-py2.py3-none-any.whl (468kB)\n",
      "Collecting PyJWT (from azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/87/8b/6a9f14b5f781697e51259d81657e6048fd31a113229cf346880bb7545565/PyJWT-1.7.1-py2.py3-none-any.whl\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
      "Collecting werkzeug>=0.11.15 (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/9f/57/92a497e38161ce40606c27a86759c6b92dd34fcdb33f64171ec559257c02/Werkzeug-0.15.4-py2.py3-none-any.whl (327kB)\n",
      "Collecting mock>=2.0.0 (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu==1.13.1->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/05/d2/f94e68be6b17f46d2c353564da56e6fb89ef09faeeff3313a046cb810ca9/mock-3.0.5-py2.py3-none-any.whl\n",
      "Collecting pycparser (from cffi>=1.4.0->horovod==0.16.1->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/68/9e/49196946aee219aead1290e00d1e7fdeab8567783e83e1b9ab5585e6206a/pycparser-2.19.tar.gz (158kB)\n",
      "Collecting idna<2.9,>=2.5 (from requests>=2.19.1->azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
      "Collecting chardet<3.1.0,>=3.0.2 (from requests>=2.19.1->azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_57642d55fb33a477d2549fe0ee5ff8fd/lib/python3.6/site-packages (from requests>=2.19.1->azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3)) (2019.6.16)\n",
      "Collecting jeepney (from SecretStorage->azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/2b/f7/ff23b9b59534f501d47c327576aadda59da5b83d76ff837e6075bc325b9f/jeepney-0.4-py3-none-any.whl (59kB)\n",
      "Collecting isodate>=0.6.0 (from msrest>=0.5.1->azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
      "Collecting requests-oauthlib>=0.5.0 (from msrest>=0.5.1->azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/c2/e2/9fd03d55ffb70fe51f587f20bcf407a6927eb121de86928b34d162f0b1ac/requests_oauthlib-1.2.0-py2.py3-none-any.whl\n",
      "Collecting websocket-client>=0.32.0 (from docker->azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n",
      "Collecting backports.weakref (from backports.tempfile->azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/88/ec/f598b633c3d5ffe267aaada57d961c94fdfa183c5c3ebda2b6d151943db6/backports.weakref-1.0.post1-py2.py3-none-any.whl\n",
      "Collecting asn1crypto>=0.21.0 (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/ea/cd/35485615f45f30a510576f1a56d1e0a7ad7bd8ab5ed7cdc600ef7cd06222/asn1crypto-0.24.0-py2.py3-none-any.whl (101kB)\n",
      "Collecting pyasn1>=0.1.1 (from ndg-httpsclient->azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/7c/c9386b82a25115cccf1903441bba3cbadcfae7b678a20167347fa8ded34c/pyasn1-0.4.5-py2.py3-none-any.whl (73kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.5.0->msrest>=0.5.1->azureml-core==1.0.43.*->azureml-defaults->-r /azureml-setup/condaenv.79tk76ed.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/16/95/699466b05b72b94a41f662dc9edf87fda4289e3602ecd42d27fcaddf7b56/oauthlib-3.0.1-py2.py3-none-any.whl (142kB)\n",
      "Building wheels for collected packages: horovod, pyyaml, termcolor, absl-py, gast, psutil, pathspec, pycparser\n",
      "  Building wheel for horovod (setup.py): started\n",
      "  Building wheel for horovod (setup.py): finished with status 'error'\n",
      "\u001b[91m  ERROR: Complete output from command /azureml-envs/azureml_57642d55fb33a477d2549fe0ee5ff8fd/bin/python -u -c 'import setuptools, tokenize;__file__='\"'\"'/tmp/pip-install-dfzblh6h/horovod/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-smc0bmar --python-tag cp36:\n",
      "\u001b[0m\u001b[91m  ERROR: \n",
      "  Installed /tmp/pip-install-dfzblh6h/horovod/.eggs/psutil-5.6.3-py3.6-linux-x86_64.egg\n",
      "  Searching for cloudpickle\n",
      "  Reading https://pypi.org/simple/cloudpickle/\n",
      "  Downloading https://files.pythonhosted.org/packages/09/f4/4a080c349c1680a2086196fcf0286a65931708156f39568ed7051e42ff6a/cloudpickle-1.2.1-py2.py3-none-any.whl#sha256=b8ba7e322f2394b9bbbdc1c976e6442c2c02acc784cb9e553cee9186166a6890\n",
      "  Best match: cloudpickle 1.2.1\n",
      "  Processing cloudpickle-1.2.1-py2.py3-none-any.whl\n",
      "  Installing cloudpickle-1.2.1-py2.py3-none-any.whl to /tmp/pip-install-dfzblh6h/horovod/.eggs\n",
      "  \n",
      "  Installed /tmp/pip-install-dfzblh6h/horovod/.eggs/cloudpickle-1.2.1-py3.6.egg\n",
      "  Searching for cffi>=1.4.0\n",
      "  Reading https://pypi.org/simple/cffi/\n",
      "  Downloading https://files.pythonhosted.org/packages/5f/bf/6aa1925384c23ffeb579e97a5569eb9abce41b6310b329352b8252cee1c3/cffi-1.12.3-cp36-cp36m-manylinux1_x86_64.whl#sha256=59b4dc008f98fc6ee2bb4fd7fc786a8d70000d058c2bbe2698275bc53a8d3fa7\n",
      "  Best match: cffi 1.12.3\n",
      "  Processing cffi-1.12.3-cp36-cp36m-manylinux1_x86_64.whl\n",
      "  Installing cffi-1.12.3-cp36-cp36m-manylinux1_x86_64.whl to /tmp/pip-install-dfzblh6h/horovod/.eggs\n",
      "  writing requirements to /tmp/pip-install-dfzblh6h/horovod/.eggs/cffi-1.12.3-py3.6-linux-x86_64.egg/EGG-INFO/requires.txt\n",
      "  \n",
      "  Installed /tmp/pip-install-dfzblh6h/horovod/.eggs/cffi-1.12.3-py3.6-linux-x86_64.egg\n",
      "  Searching for pycparser\n",
      "  Reading https://pypi.org/simple/pycparser/\n",
      "  Downloading https://files.pythonhosted.org/packages/68/9e/49196946aee219aead1290e00d1e7fdeab8567783e83e1b9ab5585e6206a/pycparser-2.19.tar.gz#sha256=a988718abfad80b6b157acce7bf130a30876d27603738ac39f140993246b25b3\n",
      "  Best match: pycparser 2.19\n",
      "  Processing pycparser-2.19.tar.gz\n",
      "  Writing /tmp/easy_install-9oyp_is1/pycparser-2.19/setup.cfg\n",
      "  Running pycparser-2.19/setup.py -q bdist_egg --dist-dir /tmp/easy_install-9oyp_is1/pycparser-2.19/egg-dist-tmp-oa6letpk\n",
      "  warning: no previously-included files found matching 'setup.pyc'\n",
      "  warning: no previously-included files matching 'yacctab.*' found under directory 'tests'\n",
      "  warning: no previously-included files matching 'lextab.*' found under directory 'tests'\n",
      "  warning: no previously-included files matching 'yacctab.*' found under directory 'examples'\n",
      "  warning: no previously-included files matching 'lextab.*' found under directory 'examples'\n",
      "  zip_safe flag not set; analyzing archive contents...\n",
      "  pycparser.ply.__pycache__.lex.cpython-36: module references __file__\n",
      "  pycparser.ply.__pycache__.lex.cpython-36: module MAY be using inspect.getsourcefile\n",
      "  pycparser.ply.__pycache__.yacc.cpython-36: module references __file__\n",
      "  pycparser.ply.__pycache__.yacc.cpython-36: module MAY be using inspect.getsourcefile\n",
      "  pycparser.ply.__pycache__.yacc.cpython-36: module MAY be using inspect.stack\n",
      "  pycparser.ply.__pycache__.ygen.cpython-36: module references __file__\n",
      "  creating /tmp/pip-install-dfzblh6h/horovod/.eggs/pycparser-2.19-py3.6.egg\n",
      "  Extracting pycparser-2.19-py3.6.egg to /tmp/pip-install-dfzblh6h/horovod/.eggs\n",
      "  \n",
      "  Installed /tmp/pip-install-dfzblh6h/horovod/.eggs/pycparser-2.19-py3.6.egg\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib.linux-x86_64-3.6\n",
      "  creating build/lib.linux-x86_64-3.6/horovod\n",
      "  copying horovod/__init__.py -> build/lib.linux-x86_64-3.6/horovod\n",
      "  creating build/lib.linux-x86_64-3.6/horovod/common\n",
      "  copying horovod/common/__init__.py -> build/lib.linux-x86_64-3.6/horovod/common\n",
      "  creating build/lib.linux-x86_64-3.6/horovod/keras\n",
      "  copying horovod/keras/__init__.py -> build/lib.linux-x86_64-3.6/horovod/keras\n",
      "  copying horovod/keras/callbacks.py -> build/lib.linux-x86_64-3.6/horovod/keras\n",
      "  creating build/lib.linux-x86_64-3.6/horovod/spark\n",
      "  copying horovod/spark/__init__.py -> build/lib.linux-x86_64-3.6/horovod/spark\n",
      "  creating build/lib.linux-x86_64-3.6/horovod/run\n",
      "  copying horovod/run/__init__.py -> build/lib.linux-x86_64-3.6/horovod/run\n",
      "  copying horovod/run/task_fn.py -> build/lib.linux-x86_64-3.6/horovod/run\n",
      "  copying horovod/run/run.py -> build/lib.linux-x86_64-3.6/horovod/run\n",
      "  creating build/lib.linux-x86_64-3.6/horovod/mxnet\n",
      "  copying horovod/mxnet/__init__.py -> build/lib.linux-x86_64-3.6/horovod/mxnet\n",
      "  copying horovod/mxnet/mpi_ops.py -> build/lib.linux-x86_64-3.6/horovod/mxnet\n",
      "  creating build/lib.linux-x86_64-3.6/horovod/_keras\n",
      "  copying horovod/_keras/__init__.py -> build/lib.linux-x86_64-3.6/horovod/_keras\n",
      "  copying horovod/_keras/callbacks.py -> build/lib.linux-x86_64-3.6/horovod/_keras\n",
      "  creating build/lib.linux-x86_64-3.6/horovod/torch\n",
      "  copying horovod/torch/__init__.py -> build/lib.linux-x86_64-3.6/horovod/torch\n",
      "  copying horovod/torch/mpi_ops.py -> build/lib.linux-x86_64-3.6/horovod/torch\n",
      "  copying horovod/torch/compression.py -> build/lib.linux-x86_64-3.6/horovod/torch\n",
      "  creating build/lib.linux-x86_64-3.6/horovod/tensorflow\n",
      "  copying horovod/tensorflow/__init__.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow\n",
      "  copying horovod/tensorflow/util.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow\n",
      "  copying horovod/tensorflow/mpi_ops.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow\n",
      "  copying horovod/tensorflow/compression.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow\n",
      "  creating build/lib.linux-x86_64-3.6/horovod/spark/driver\n",
      "  copying horovod/spark/driver/__init__.py -> build/lib.linux-x86_64-3.6/horovod/spark/driver\n",
      "  copying horovod/spark/driver/driver_service.py -> build/lib.linux-x86_64-3.6/horovod/spark/driver\n",
      "  copying horovod/spark/driver/job_id.py -> build/lib.linux-x86_64-3.6/horovod/spark/driver\n",
      "  copying horovod/spark/driver/mpirun_rsh.py -> build/lib.linux-x86_64-3.6/horovod/spark/driver\n",
      "  creating build/lib.linux-x86_64-3.6/horovod/spark/task\n",
      "  copying horovod/spark/task/__init__.py -> build/lib.linux-x86_64-3.6/horovod/spark/task\n",
      "  copying horovod/spark/task/mpirun_exec_fn.py -> build/lib.linux-x86_64-3.6/horovod/spark/task\n",
      "  copying horovod/spark/task/task_service.py -> build/lib.linux-x86_64-3.6/horovod/spark/task\n",
      "  creating build/lib.linux-x86_64-3.6/horovod/run/common\n",
      "  copying horovod/run/common/__init__.py -> build/lib.linux-x86_64-3.6/horovod/run/common\n",
      "  creating build/lib.linux-x86_64-3.6/horovod/run/util\n",
      "  copying horovod/run/util/cache.py -> build/lib.linux-x86_64-3.6/horovod/run/util\n",
      "  copying horovod/run/util/threads.py -> build/lib.linux-x86_64-3.6/horovod/run/util\n",
      "  copying horovod/run/util/__init__.py -> build/lib.linux-x86_64-3.6/horovod/run/util\n",
      "  copying horovod/run/util/network.py -> build/lib.linux-x86_64-3.6/horovod/run/util\n",
      "  creating build/lib.linux-x86_64-3.6/horovod/run/driver\n",
      "  copying horovod/run/driver/__init__.py -> build/lib.linux-x86_64-3.6/horovod/run/driver\n",
      "  copying horovod/run/driver/driver_service.py -> build/lib.linux-x86_64-3.6/horovod/run/driver\n",
      "  creating build/lib.linux-x86_64-3.6/horovod/run/task\n",
      "  copying horovod/run/task/__init__.py -> build/lib.linux-x86_64-3.6/horovod/run/task\n",
      "  copying horovod/run/task/task_service.py -> build/lib.linux-x86_64-3.6/horovod/run/task\n",
      "  creating build/lib.linux-x86_64-3.6/horovod/run/common/util\n",
      "  copying horovod/run/common/util/__init__.py -> build/lib.linux-x86_64-3.6/horovod/run/common/util\n",
      "  copying horovod/run/common/util/timeout.py -> build/lib.linux-x86_64-3.6/horovod/run/common/util\n",
      "  copying horovod/run/common/util/secret.py -> build/lib.linux-x86_64-3.6/horovod/run/common/util\n",
      "  copying horovod/run/common/util/host_hash.py -> build/lib.linux-x86_64-3.6/horovod/run/common/util\n",
      "  copying horovod/run/common/util/safe_shell_exec.py -> build/lib.linux-x86_64-3.6/horovod/run/common/util\n",
      "  copying horovod/run/common/util/network.py -> build/lib.linux-x86_64-3.6/horovod/run/common/util\n",
      "  copying horovod/run/common/util/codec.py -> build/lib.linux-x86_64-3.6/horovod/run/common/util\n",
      "  creating build/lib.linux-x86_64-3.6/horovod/run/common/service\n",
      "  copying horovod/run/common/service/__init__.py -> build/lib.linux-x86_64-3.6/horovod/run/common/service\n",
      "  copying horovod/run/common/service/driver_service.py -> build/lib.linux-x86_64-3.6/horovod/run/common/service\n",
      "  copying horovod/run/common/service/task_service.py -> build/lib.linux-x86_64-3.6/horovod/run/common/service\n",
      "  creating build/lib.linux-x86_64-3.6/horovod/torch/mpi_lib_impl\n",
      "  copying horovod/torch/mpi_lib_impl/__init__.py -> build/lib.linux-x86_64-3.6/horovod/torch/mpi_lib_impl\n",
      "  creating build/lib.linux-x86_64-3.6/horovod/torch/mpi_lib\n",
      "  copying horovod/torch/mpi_lib/__init__.py -> build/lib.linux-x86_64-3.6/horovod/torch/mpi_lib\n",
      "  creating build/lib.linux-x86_64-3.6/horovod/tensorflow/keras\n",
      "  copying horovod/tensorflow/keras/__init__.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow/keras\n",
      "  copying horovod/tensorflow/keras/callbacks.py -> build/lib.linux-x86_64-3.6/horovod/tensorflow/keras\n",
      "  running build_ext\n",
      "  gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -std=c++11 -fPIC -O2 -Wall -mf16c -mavx -I/azureml-envs/azureml_57642d55fb33a477d2549fe0ee5ff8fd/include/python3.6m -c build/temp.linux-x86_64-3.6/test_compile/test_cpp_flags.cc -o build/temp.linux-x86_64-3.6/test_compile/test_cpp_flags.o\n",
      "  cc1plus: warning: command line option â€˜-Wstrict-prototypesâ€™ is valid for C/ObjC but not for C++\n",
      "  gcc -pthread -shared -L/azureml-envs/azureml_57642d55fb33a477d2549fe0ee5ff8fd/lib -Wl,-rpath=/azureml-envs/azureml_57642d55fb33a477d2549fe0ee5ff8fd/lib,--no-as-needed -L/azureml-envs/azureml_57642d55fb33a477d2549fe0ee5ff8fd/lib -Wl,-rpath=/azureml-envs/azureml_57642d55fb33a477d2549fe0ee5ff8fd/lib,--no-as-needed build/temp.linux-x86_64-3.6/test_compile/test_cpp_flags.o -L/azureml-envs/azureml_57642d55fb33a477d2549fe0ee5ff8fd/lib -o build/temp.linux-x86_64-3.6/test_compile/test_cpp_flags.so\n",
      "  gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/azureml-envs/azureml_57642d55fb33a477d2549fe0ee5ff8fd/include/python3.6m -c build/temp.linux-x86_64-3.6/test_compile/test_link_flags.cc -o build/temp.linux-x86_64-3.6/test_compile/test_link_flags.o\n",
      "  cc1plus: warning: command line option â€˜-Wstrict-prototypesâ€™ is valid for C/ObjC but not for C++\n",
      "  gcc -pthread -shared -L/azureml-envs/azureml_57642d55fb33a477d2549fe0ee5ff8fd/lib -Wl,-rpath=/azureml-envs/azureml_57642d55fb33a477d2549fe0ee5ff8fd/lib,--no-as-needed -L/azureml-envs/azureml_57642d55fb33a477d2549fe0ee5ff8fd/lib -Wl,-rpath=/azureml-envs/azureml_57642d55fb33a477d2549fe0ee5ff8fd/lib,--no-as-needed -Wl,--version-script=horovod.lds build/temp.linux-x86_64-3.6/test_compile/test_link_flags.o -L/azureml-envs/azureml_57642d55fb33a477d2549fe0ee5ff8fd/lib -o build/temp.linux-x86_64-3.6/test_compile/test_link_flags.so\n",
      "  INFO: Unable to build TensorFlow plugin, will skip it.\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"/tmp/pip-install-dfzblh6h/horovod/setup.py\", line 55, in check_tf_version\n",
      "      import tensorflow as tf\n",
      "  ModuleNotFoundError: No module named 'tensorflow'\n",
      "  \n",
      "  During handling of the above exception, another exception occurred:\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"/tmp/pip-install-dfzblh6h/horovod/setup.py\", line 909, in build_extensions\n",
      "      build_tf_extension(self, options)\n",
      "    File \"/tmp/pip-install-dfzblh6h/horovod/setup.py\", line 608, in build_tf_extension\n",
      "      check_tf_version()\n",
      "    File \"/tmp/pip-install-dfzblh6h/horovod/setup.py\", line 62, in check_tf_version\n",
      "      'import tensorflow failed, is it installed?\\n\\n%s' % traceback.format_exc())\n",
      "  distutils.errors.DistutilsPlatformError: import tensorflow failed, is it installed?\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"/tmp/pip-install-dfzblh6h/horovod/setup.py\", line 55, in check_tf_version\n",
      "      import tensorflow as tf\n",
      "  ModuleNotFoundError: No module named 'tensorflow'\n",
      "  \n",
      "  \n",
      "  INFO: Unable to build PyTorch plugin, will skip it.\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"/tmp/pip-install-dfzblh6h/horovod/setup.py\", line 711, in check_torch_version\n",
      "      import torch\n",
      "  ModuleNotFoundError: No module named 'torch'\n",
      "  \n",
      "  During handling of the above exception, another exception occurred:\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"/tmp/pip-install-dfzblh6h/horovod/setup.py\", line 920, in build_extensions\n",
      "      torch_version = check_torch_version()\n",
      "    File \"/tmp/pip-install-dfzblh6h/horovod/setup.py\", line 718, in check_torch_version\n",
      "      'import torch failed, is it installed?\\n\\n%s' % traceback.format_exc())\n",
      "  distutils.errors.DistutilsPlatformError: import torch failed, is it installed?\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"/tmp/pip-install-dfzblh6h/horovod/setup.py\", line 711, in check_torch_version\n",
      "      import torch\n",
      "  ModuleNotFoundError: No module named 'torch'\n",
      "  \n",
      "  \n",
      "  INFO: Unable to build MXNet plugin, will skip it.\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"/tmp/pip-install-dfzblh6h/horovod/setup.py\", line 71, in check_mx_version\n",
      "      import mxnet as mx\n",
      "  ModuleNotFoundError: No module named 'mxnet'\n",
      "  \n",
      "  During handling of the above exception, another exception occurred:\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"/tmp/pip-install-dfzblh6h/horovod/setup.py\", line 935, in build_extensions\n",
      "      build_mx_extension(self, options)\n",
      "    File \"/tmp/pip-install-dfzblh6h/horovod/setup.py\", line 672, in build_mx_extension\n",
      "      check_mx_version()\n",
      "    File \"/tmp/pip-install-dfzblh6h/horovod/setup.py\", line 78, in check_mx_version\n",
      "      'import mxnet failed, is it installed?\\n\\n%s' % traceback.format_exc())\n",
      "  distutils.errors.DistutilsPlatformError: import mxnet failed, is it installed?\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"/tmp/pip-install-dfzblh6h/horovod/setup.py\", line 71, in check_mx_version\n",
      "      import mxnet as mx\n",
      "  ModuleNotFoundError: No module named 'mxnet'\n",
      "  \n",
      "  \n",
      "  error: None of TensorFlow, PyTorch, or MXNet plugins were built. See errors above.\n",
      "  ----------------------------------------\u001b[0m  Running setup.py clean for horovod\n",
      "\u001b[91m\n",
      "  ERROR: Failed building wheel for horovod\n",
      "\u001b[0m  Building wheel for pyyaml (setup.py): started\n",
      "  Building wheel for pyyaml (setup.py): finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/16/27/a1/775c62ddea7bfa62324fd1f65847ed31c55dadb6051481ba3f\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Building wheel for absl-py (setup.py): started\n",
      "  Building wheel for absl-py (setup.py): finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/ee/98/38/46cbcc5a93cfea5492d19c38562691ddb23b940176c14f7b48\n",
      "  Building wheel for gast (setup.py): started\n",
      "  Building wheel for gast (setup.py): finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "  Building wheel for psutil (setup.py): started\n",
      "  Building wheel for psutil (setup.py): finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/90/7e/74/bb640d77775e6b6a78bcc3120f9fea4d2a28b2706de1cff37d\n",
      "  Building wheel for pathspec (setup.py): started\n",
      "  Building wheel for pathspec (setup.py): finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/45/cb/7e/ce6e6062c69446e39e328170524ca8213498bc66a74c6a210b\n",
      "  Building wheel for pycparser (setup.py): started\n",
      "  Building wheel for pycparser (setup.py): finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/f2/9a/90/de94f8556265ddc9d9c8b271b0f63e57b26fb1d67a45564511\n",
      "Successfully built pyyaml termcolor absl-py gast psutil pathspec pycparser\n",
      "Failed to build horovod\n",
      "Installing collected packages: pyyaml, numpy, six, keras-preprocessing, h5py, keras-applications, scipy, keras, kiwisolver, pyparsing, cycler, python-dateutil, matplotlib, applicationinsights, pytz, idna, urllib3, chardet, requests, jeepney, asn1crypto, pycparser, cffi, cryptography, SecretStorage, azure-common, PyJWT, adal, isodate, oauthlib, requests-oauthlib, msrest, msrestazure, azure-mgmt-storage, pathspec, azure-graphrbac, websocket-client, docker, azure-mgmt-keyvault, jsonpickle, backports.weakref, backports.tempfile, contextlib2, pyopenssl, azure-mgmt-containerregistry, pyasn1, ndg-httpsclient, jmespath, azure-mgmt-authorization, ruamel.yaml, azure-mgmt-resource, azureml-core, azureml-defaults, termcolor, protobuf, astor, absl-py, grpcio, markdown, werkzeug, tensorboard, mock, tensorflow-estimator, gast, tensorflow-gpu, cloudpickle, psutil, horovod\n",
      "  Running setup.py install for horovod: started\n",
      "    Running setup.py install for horovod: finished with status 'done'\n",
      "Successfully installed PyJWT-1.7.1 SecretStorage-3.1.1 absl-py-0.7.1 adal-1.2.1 applicationinsights-0.11.9 asn1crypto-0.24.0 astor-0.8.0 azure-common-1.1.23 azure-graphrbac-0.61.1 azure-mgmt-authorization-0.52.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.0.0 azure-mgmt-resource-3.0.0 azure-mgmt-storage-4.0.0 azureml-core-1.0.43.1 azureml-defaults-1.0.43 backports.tempfile-1.0 backports.weakref-1.0.post1 cffi-1.12.3 chardet-3.0.4 cloudpickle-1.2.1 contextlib2-0.5.5 cryptography-2.7 cycler-0.10.0 docker-4.0.2 gast-0.2.2 grpcio-1.21.1 h5py-2.9.0 horovod-0.16.1 idna-2.8 isodate-0.6.0 jeepney-0.4 jmespath-0.9.4 jsonpickle-1.2 keras-2.2.4 keras-applications-1.0.8 keras-preprocessing-1.1.0 kiwisolver-1.1.0 markdown-3.1.1 matplotlib-3.1.0 mock-3.0.5 msrest-0.6.8 msrestazure-0.6.1 ndg-httpsclient-0.5.1 numpy-1.16.4 oauthlib-3.0.1 pathspec-0.5.9 protobuf-3.8.0 psutil-5.6.3 pyasn1-0.4.5 pycparser-2.19 pyopenssl-19.0.0 pyparsing-2.4.0 python-dateutil-2.8.0 pytz-2019.1 pyyaml-5.1.1 requests-2.22.0 requests-oauthlib-1.2.0 ruamel.yaml-0.15.89 scipy-1.3.0 six-1.12.0 tensorboard-1.13.1 tensorflow-estimator-1.13.0 tensorflow-gpu-1.13.1 termcolor-1.1.0 urllib3-1.25.3 websocket-client-0.56.0 werkzeug-0.15.4\n",
      "\u001b[91m\n",
      "\u001b[0m#\n",
      "# To activate this environment, use:\n",
      "# > source activate /azureml-envs/azureml_57642d55fb33a477d2549fe0ee5ff8fd\n",
      "#\n",
      "# To deactivate an active environment, use:\n",
      "# > source deactivate\n",
      "#\n",
      "\n",
      "Removing intermediate container 70d23d2b1d15\n",
      " ---> 2c60f208e404\n",
      "Step 9/14 : ENV PATH /azureml-envs/azureml_57642d55fb33a477d2549fe0ee5ff8fd/bin:$PATH\n",
      " ---> Running in 578d8f7c185b\n",
      "Removing intermediate container 578d8f7c185b\n",
      " ---> 9e01e3d7f0a6\n",
      "Step 10/14 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_57642d55fb33a477d2549fe0ee5ff8fd\n",
      " ---> Running in 8f8840e953a6\n",
      "Removing intermediate container 8f8840e953a6\n",
      " ---> 2aef089bc8cc\n",
      "Step 11/14 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_57642d55fb33a477d2549fe0ee5ff8fd/lib:$LD_LIBRARY_PATH\n",
      " ---> Running in 4e798fc2461a\n",
      "Removing intermediate container 4e798fc2461a\n",
      " ---> 46d4904c02bd\n",
      "Step 12/14 : COPY azureml-setup/spark_cache.py azureml-setup/log4j.properties /azureml-setup/\n",
      " ---> 2d509d839b1c\n",
      "Step 13/14 : ENV AZUREML_ENVIRONMENT_IMAGE True\n",
      " ---> Running in 6a6006f81f54\n",
      "Removing intermediate container 6a6006f81f54\n",
      " ---> 2926626b8e09\n",
      "Step 14/14 : CMD [\"bash\"]\n",
      " ---> Running in 9dd4596f60b4\n",
      "Removing intermediate container 9dd4596f60b4\n",
      " ---> cc0b6708805b\n",
      "Successfully built cc0b6708805b\n",
      "Successfully tagged azuremlexperd4996c19.azurecr.io/azureml/azureml_e639d7869712879dfdb1d61005d0d6e0:latest\n",
      "2019/06/25 14:50:48 Successfully executed container: acb_step_0\n",
      "2019/06/25 14:50:48 Executing step ID: acb_step_1. Timeout(sec): 1800, Working directory: '', Network: 'acb_default_network'\n",
      "2019/06/25 14:50:48 Pushing image: azuremlexperd4996c19.azurecr.io/azureml/azureml_e639d7869712879dfdb1d61005d0d6e0:latest, attempt 1\n",
      "The push refers to repository [azuremlexperd4996c19.azurecr.io/azureml/azureml_e639d7869712879dfdb1d61005d0d6e0]\n",
      "3ff443bf189d: Preparing\n",
      "beac226414c1: Preparing\n",
      "e6440121aced: Preparing\n",
      "c4712b0b65af: Preparing\n",
      "a9004e25d8d8: Preparing\n",
      "9ff47905351e: Preparing\n",
      "8d0ffb82cd9c: Preparing\n",
      "7fd0e7b966d8: Preparing\n",
      "91d341ced524: Preparing\n",
      "950abdfbc65e: Preparing\n",
      "11210dd81681: Preparing\n",
      "5d6cca69c100: Preparing\n",
      "31b946ea17bb: Preparing\n",
      "ef3304f85894: Preparing\n",
      "cacd9b90c818: Preparing\n",
      "221e6befd0c5: Preparing\n",
      "478462fe5e15: Preparing\n",
      "297fd071ca2f: Preparing\n",
      "2f0d1e8214b2: Preparing\n",
      "7dd604ffa87f: Preparing\n",
      "aa54c2bc1229: Preparing\n",
      "9ff47905351e: Waiting\n",
      "8d0ffb82cd9c: Waiting\n",
      "7fd0e7b966d8: Waiting\n",
      "91d341ced524: Waiting\n",
      "950abdfbc65e: Waiting\n",
      "11210dd81681: Waiting\n",
      "5d6cca69c100: Waiting\n",
      "31b946ea17bb: Waiting\n",
      "ef3304f85894: Waiting\n",
      "cacd9b90c818: Waiting\n",
      "221e6befd0c5: Waiting\n",
      "478462fe5e15: Waiting\n",
      "297fd071ca2f: Waiting\n",
      "2f0d1e8214b2: Waiting\n",
      "7dd604ffa87f: Waiting\n",
      "aa54c2bc1229: Waiting\n",
      "3ff443bf189d: Pushed\n",
      "a9004e25d8d8: Pushed\n",
      "c4712b0b65af: Pushed\n",
      "e6440121aced: Pushed\n",
      "9ff47905351e: Pushed\n",
      "8d0ffb82cd9c: Pushed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7fd0e7b966d8: Pushed\n",
      "950abdfbc65e: Pushed\n",
      "11210dd81681: Pushed\n",
      "91d341ced524: Pushed\n",
      "cacd9b90c818: Pushed\n",
      "221e6befd0c5: Pushed\n",
      "478462fe5e15: Pushed\n",
      "297fd071ca2f: Pushed\n",
      "2f0d1e8214b2: Pushed\n",
      "7dd604ffa87f: Pushed\n",
      "5d6cca69c100: Pushed\n",
      "aa54c2bc1229: Pushed\n",
      "ef3304f85894: Pushed\n",
      "31b946ea17bb: Pushed\n",
      "beac226414c1: Pushed\n",
      "latest: digest: sha256:5578a588a32e1fa3656937bdc469e292e2be64c8ab5b8af568cd7df7e7ff74b3 size: 4728\n",
      "2019/06/25 14:54:47 Successfully pushed image: azuremlexperd4996c19.azurecr.io/azureml/azureml_e639d7869712879dfdb1d61005d0d6e0:latest\n",
      "2019/06/25 14:54:47 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 286.238073)\n",
      "2019/06/25 14:54:47 Populating digests for step ID: acb_step_0...\n",
      "2019/06/25 14:54:49 Successfully populated digests for step ID: acb_step_0\n",
      "2019/06/25 14:54:49 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 238.939073)\n",
      "2019/06/25 14:54:49 The following dependencies were found:\n",
      "2019/06/25 14:54:49 \n",
      "- image:\n",
      "    registry: azuremlexperd4996c19.azurecr.io\n",
      "    repository: azureml/azureml_e639d7869712879dfdb1d61005d0d6e0\n",
      "    tag: latest\n",
      "    digest: sha256:5578a588a32e1fa3656937bdc469e292e2be64c8ab5b8af568cd7df7e7ff74b3\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/base-gpu\n",
      "    tag: intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04\n",
      "    digest: sha256:a36e319c7539a8e19c42b4c010da91e8fe776158b428b2f6facdf14c0469b6d3\n",
      "  git: {}\n",
      "\n",
      "\n",
      "Run ID: cg2 was successful after 8m52s\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "\n",
      "Using TensorFlow backend.\n",
      "Keras version: 2.2.4\n",
      "Tensorflow version: 1.13.1\n",
      "training dataset is stored here: /mnt/batch/tasks/shared/LS_root/jobs/azure-ml-experiments/azureml/keras-mnist_1561473949_451ed77e/mounts/workspaceblobstore/mnist\n",
      "(60000, 784)\n",
      "(60000, 10)\n",
      "(10000, 784)\n",
      "(10000, 10)\n",
      "WARNING:tensorflow:From /azureml-envs/azureml_57642d55fb33a477d2549fe0ee5ff8fd/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /azureml-envs/azureml_57642d55fb33a477d2549fe0ee5ff8fd/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "2019-06-25 15:00:56.634286: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-06-25 15:00:57.090308: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x460f3a0 executing computations on platform CUDA. Devices:\n",
      "2019-06-25 15:00:57.090348: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
      "2019-06-25 15:00:57.092520: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2596990000 Hz\n",
      "2019-06-25 15:00:57.093321: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x4677520 executing computations on platform Host. Devices:\n",
      "2019-06-25 15:00:57.093344: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-06-25 15:00:57.093889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 825f:00:00.0\n",
      "totalMemory: 11.17GiB freeMemory: 11.11GiB\n",
      "2019-06-25 15:00:57.093909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2019-06-25 15:00:57.096683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-06-25 15:00:57.096706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2019-06-25 15:00:57.096714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2019-06-25 15:00:57.097235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 825f:00:00.0, compute capability: 3.7)\n",
      "2019-06-25 15:00:57.725737: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
      " - 5s - loss: 0.2119 - acc: 0.9362 - val_loss: 0.1037 - val_acc: 0.9688\n",
      "Epoch 2/20\n",
      " - 4s - loss: 0.0898 - acc: 0.9734 - val_loss: 0.0927 - val_acc: 0.9718\n",
      "Epoch 3/20\n",
      " - 4s - loss: 0.0641 - acc: 0.9812 - val_loss: 0.0821 - val_acc: 0.9775\n",
      "Epoch 4/20\n",
      " - 3s - loss: 0.0497 - acc: 0.9855 - val_loss: 0.0915 - val_acc: 0.9759\n",
      "Epoch 5/20\n",
      " - 3s - loss: 0.0385 - acc: 0.9889 - val_loss: 0.0839 - val_acc: 0.9787\n",
      "Epoch 6/20\n",
      " - 3s - loss: 0.0346 - acc: 0.9903 - val_loss: 0.0967 - val_acc: 0.9778\n",
      "Epoch 7/20\n",
      " - 3s - loss: 0.0267 - acc: 0.9924 - val_loss: 0.1061 - val_acc: 0.9767\n",
      "Epoch 8/20\n",
      " - 3s - loss: 0.0222 - acc: 0.9935 - val_loss: 0.1006 - val_acc: 0.9798\n",
      "Epoch 9/20\n",
      " - 4s - loss: 0.0192 - acc: 0.9944 - val_loss: 0.1142 - val_acc: 0.9790\n",
      "Epoch 10/20\n",
      " - 3s - loss: 0.0161 - acc: 0.9957 - val_loss: 0.1261 - val_acc: 0.9790\n",
      "Epoch 11/20\n",
      " - 4s - loss: 0.0150 - acc: 0.9959 - val_loss: 0.1156 - val_acc: 0.9801\n",
      "Epoch 12/20\n",
      " - 4s - loss: 0.0118 - acc: 0.9969 - val_loss: 0.1202 - val_acc: 0.9819\n",
      "Epoch 13/20\n",
      " - 4s - loss: 0.0122 - acc: 0.9968 - val_loss: 0.1350 - val_acc: 0.9790\n",
      "Epoch 14/20\n",
      " - 4s - loss: 0.0110 - acc: 0.9970 - val_loss: 0.1236 - val_acc: 0.9812\n",
      "Epoch 15/20\n",
      " - 4s - loss: 0.0095 - acc: 0.9975 - val_loss: 0.1356 - val_acc: 0.9812\n",
      "Epoch 16/20\n",
      " - 4s - loss: 0.0087 - acc: 0.9974 - val_loss: 0.1256 - val_acc: 0.9825\n",
      "Epoch 17/20\n",
      " - 4s - loss: 0.0082 - acc: 0.9980 - val_loss: 0.1265 - val_acc: 0.9819\n",
      "Epoch 18/20\n",
      " - 4s - loss: 0.0069 - acc: 0.9982 - val_loss: 0.1599 - val_acc: 0.9790\n",
      "Epoch 19/20\n",
      " - 4s - loss: 0.0063 - acc: 0.9985 - val_loss: 0.1500 - val_acc: 0.9817\n",
      "Epoch 20/20\n",
      " - 4s - loss: 0.0055 - acc: 0.9986 - val_loss: 0.1387 - val_acc: 0.9824\n",
      "Test loss: 0.1386978552624188\n",
      "Test accuracy: 0.9824\n",
      "model saved in ./outputs/model folder\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Logging experiment finalizing status in history service.\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.2549126148223877 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-22:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/psfriso/anaconda3/envs/azure_ml/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/psfriso/anaconda3/envs/azure_ml/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/psfriso/anaconda3/envs/azure_ml/lib/python3.6/multiprocessing/pool.py\", line 479, in _handle_results\n",
      "    cache[job]._set(i, obj)\n",
      "  File \"/Users/psfriso/anaconda3/envs/azure_ml/lib/python3.6/multiprocessing/pool.py\", line 649, in _set\n",
      "    self._callback(self._value)\n",
      "  File \"/Users/psfriso/anaconda3/envs/azure_ml/lib/python3.6/site-packages/azureml/widgets/_userrun/_run_details.py\", line 503, in _update_metrics\n",
      "    self.widget_instance.run_metrics = result\n",
      "  File \"/Users/psfriso/anaconda3/envs/azure_ml/lib/python3.6/site-packages/traitlets/traitlets.py\", line 585, in __set__\n",
      "    self.set(obj, value)\n",
      "  File \"/Users/psfriso/anaconda3/envs/azure_ml/lib/python3.6/site-packages/traitlets/traitlets.py\", line 574, in set\n",
      "    obj._notify_trait(self.name, old_value, new_value)\n",
      "  File \"/Users/psfriso/anaconda3/envs/azure_ml/lib/python3.6/site-packages/traitlets/traitlets.py\", line 1139, in _notify_trait\n",
      "    type='change',\n",
      "  File \"/Users/psfriso/anaconda3/envs/azure_ml/lib/python3.6/site-packages/ipywidgets/widgets/widget.py\", line 599, in notify_change\n",
      "    self.send_state(key=name)\n",
      "  File \"/Users/psfriso/anaconda3/envs/azure_ml/lib/python3.6/site-packages/ipywidgets/widgets/widget.py\", line 484, in send_state\n",
      "    self._send(msg, buffers=buffers)\n",
      "  File \"/Users/psfriso/anaconda3/envs/azure_ml/lib/python3.6/site-packages/ipywidgets/widgets/widget.py\", line 729, in _send\n",
      "    self.comm.send(data=msg, buffers=buffers)\n",
      "  File \"/Users/psfriso/anaconda3/envs/azure_ml/lib/python3.6/site-packages/ipykernel/comm/comm.py\", line 121, in send\n",
      "    data=data, metadata=metadata, buffers=buffers,\n",
      "  File \"/Users/psfriso/anaconda3/envs/azure_ml/lib/python3.6/site-packages/ipykernel/comm/comm.py\", line 65, in _publish_msg\n",
      "    content = json_clean(dict(data=data, comm_id=self.comm_id, **keys))\n",
      "  File \"/Users/psfriso/anaconda3/envs/azure_ml/lib/python3.6/site-packages/ipykernel/jsonutil.py\", line 191, in json_clean\n",
      "    out[unicode_type(k)] = json_clean(v)\n",
      "  File \"/Users/psfriso/anaconda3/envs/azure_ml/lib/python3.6/site-packages/ipykernel/jsonutil.py\", line 191, in json_clean\n",
      "    out[unicode_type(k)] = json_clean(v)\n",
      "  File \"/Users/psfriso/anaconda3/envs/azure_ml/lib/python3.6/site-packages/ipykernel/jsonutil.py\", line 191, in json_clean\n",
      "    out[unicode_type(k)] = json_clean(v)\n",
      "  File \"/Users/psfriso/anaconda3/envs/azure_ml/lib/python3.6/site-packages/ipykernel/jsonutil.py\", line 177, in json_clean\n",
      "    return [json_clean(x) for x in obj]\n",
      "  File \"/Users/psfriso/anaconda3/envs/azure_ml/lib/python3.6/site-packages/ipykernel/jsonutil.py\", line 177, in <listcomp>\n",
      "    return [json_clean(x) for x in obj]\n",
      "  File \"/Users/psfriso/anaconda3/envs/azure_ml/lib/python3.6/site-packages/ipykernel/jsonutil.py\", line 191, in json_clean\n",
      "    out[unicode_type(k)] = json_clean(v)\n",
      "  File \"/Users/psfriso/anaconda3/envs/azure_ml/lib/python3.6/site-packages/ipykernel/jsonutil.py\", line 177, in json_clean\n",
      "    return [json_clean(x) for x in obj]\n",
      "  File \"/Users/psfriso/anaconda3/envs/azure_ml/lib/python3.6/site-packages/ipykernel/jsonutil.py\", line 177, in <listcomp>\n",
      "    return [json_clean(x) for x in obj]\n",
      "  File \"/Users/psfriso/anaconda3/envs/azure_ml/lib/python3.6/site-packages/ipykernel/jsonutil.py\", line 191, in json_clean\n",
      "    out[unicode_type(k)] = json_clean(v)\n",
      "  File \"/Users/psfriso/anaconda3/envs/azure_ml/lib/python3.6/site-packages/ipykernel/jsonutil.py\", line 177, in json_clean\n",
      "    return [json_clean(x) for x in obj]\n",
      "  File \"/Users/psfriso/anaconda3/envs/azure_ml/lib/python3.6/site-packages/ipykernel/jsonutil.py\", line 177, in <listcomp>\n",
      "    return [json_clean(x) for x in obj]\n",
      "  File \"/Users/psfriso/anaconda3/envs/azure_ml/lib/python3.6/site-packages/ipykernel/jsonutil.py\", line 197, in json_clean\n",
      "    raise ValueError(\"Can't clean for JSON: %r\" % obj)\n",
      "ValueError: Can't clean for JSON: Artifact(data_location=aml://artifactId/ExperimentRun/dcid.keras-mnist_1561473949_451ed77e/Accuracy vs Loss_1561474928.png, filename=Accuracy vs Loss_1561474928.png, metric_type=azureml.v2.image)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: keras-mnist_1561473949_451ed77e\n",
      "Web View: https://mlworkspace.azure.ai/portal/subscriptions/79ec9c01-599f-4707-82f9-31b2d938f2e5/resourceGroups/pedro-test/providers/Microsoft.MachineLearningServices/workspaces/azure-ml-experiments/experiments/keras-mnist/runs/keras-mnist_1561473949_451ed77e\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'keras-mnist_1561473949_451ed77e',\n",
       " 'target': 'gpu-cluster',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2019-06-25T14:59:01.717853Z',\n",
       " 'endTimeUtc': '2019-06-25T15:02:23.08799Z',\n",
       " 'properties': {'azureml.runsource': 'experiment',\n",
       "  'AzureML.DerivedImageName': 'azureml/azureml_e639d7869712879dfdb1d61005d0d6e0',\n",
       "  'ContentSnapshotId': 'bcde896a-e0a8-4257-8aa0-1f3f89f4555e'},\n",
       " 'runDefinition': {'script': 'keras_mnist.py',\n",
       "  'arguments': ['--data-folder',\n",
       "   '$AZUREML_DATAREFERENCE_c236cf1297ba41378d4ce4d49deba0cc',\n",
       "   '--batch-size',\n",
       "   '50',\n",
       "   '--first-layer-neurons',\n",
       "   '300',\n",
       "   '--second-layer-neurons',\n",
       "   '100',\n",
       "   '--learning-rate',\n",
       "   '0.001'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'gpu-cluster',\n",
       "  'dataReferences': {'c236cf1297ba41378d4ce4d49deba0cc': {'dataStoreName': 'workspaceblobstore',\n",
       "    'mode': 'Mount',\n",
       "    'pathOnDataStore': 'mnist',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False}},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'Experiment keras-mnist Environment',\n",
       "   'version': 'Autosave_2019-06-25T14:45:53Z_0ff07d2c',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'name': 'project_environment',\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['keras',\n",
       "        'matplotlib',\n",
       "        'azureml-defaults',\n",
       "        'tensorflow-gpu==1.13.1',\n",
       "        'horovod==0.16.1']}],\n",
       "     'channels': ['conda-forge']},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE',\n",
       "    'NCCL_SOCKET_IFNAME': '^docker0'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base-gpu:intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04',\n",
       "    'enabled': True,\n",
       "    'sharedVolumes': True,\n",
       "    'gpuSupport': True,\n",
       "    'shmSize': '1g',\n",
       "    'arguments': [],\n",
       "    'baseImageRegistry': {'address': None,\n",
       "     'username': None,\n",
       "     'password': None}},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': False}},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'vmPriority': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None},\n",
       " 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://azuremlestorage9451e43f9.blob.core.windows.net/azureml/ExperimentRun/dcid.keras-mnist_1561473949_451ed77e/azureml-logs/20_image_build_log.txt?sv=2018-03-28&sr=b&sig=LyH0iW8tAEKfDbHo4vUPHnvmaAliLqOfDb1LoYpXZ2s%3D&st=2019-06-25T14%3A52%3A25Z&se=2019-06-25T23%3A02%3A25Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://azuremlestorage9451e43f9.blob.core.windows.net/azureml/ExperimentRun/dcid.keras-mnist_1561473949_451ed77e/azureml-logs/70_driver_log.txt?sv=2018-03-28&sr=b&sig=lrxAS3X07IVqjvb3NHIadgljLH1pcBYbdraSnQyizPs%3D&st=2019-06-25T14%3A52%3A25Z&se=2019-06-25T23%3A02%3A25Z&sp=r',\n",
       "  'azureml-logs/driver_log.txt': 'https://azuremlestorage9451e43f9.blob.core.windows.net/azureml/ExperimentRun/dcid.keras-mnist_1561473949_451ed77e/azureml-logs/driver_log.txt?sv=2018-03-28&sr=b&sig=nl6hjos8z%2FMMmZkn6WPhimHr2eAbtFHLKdFwORoEVi0%3D&st=2019-06-25T14%3A52%3A25Z&se=2019-06-25T23%3A02%3A25Z&sp=r',\n",
       "  'azureml-logs/55_batchai_stdout-job_post.txt': 'https://azuremlestorage9451e43f9.blob.core.windows.net/azureml/ExperimentRun/dcid.keras-mnist_1561473949_451ed77e/azureml-logs/55_batchai_stdout-job_post.txt?sv=2018-03-28&sr=b&sig=mk83DDEoU9DDrU4GPjNJR1uSNAvLsF4%2FaXdJloVlZm8%3D&st=2019-06-25T14%3A52%3A25Z&se=2019-06-25T23%3A02%3A25Z&sp=r',\n",
       "  'azureml-logs/56_batchai_stderr.txt': 'https://azuremlestorage9451e43f9.blob.core.windows.net/azureml/ExperimentRun/dcid.keras-mnist_1561473949_451ed77e/azureml-logs/56_batchai_stderr.txt?sv=2018-03-28&sr=b&sig=Dcasd0fjpAYr5W26cy1NojqeVzDSWnoqeq0cTmLolvE%3D&st=2019-06-25T14%3A52%3A25Z&se=2019-06-25T23%3A02%3A25Z&sp=r',\n",
       "  'azureml-logs/55_batchai_execution.txt': 'https://azuremlestorage9451e43f9.blob.core.windows.net/azureml/ExperimentRun/dcid.keras-mnist_1561473949_451ed77e/azureml-logs/55_batchai_execution.txt?sv=2018-03-28&sr=b&sig=6LC8QLgPL4XXdOP%2FMkTCvaeUWOImgRMH3TdDcAuRGzI%3D&st=2019-06-25T14%3A52%3A25Z&se=2019-06-25T23%3A02%3A25Z&sp=r',\n",
       "  'azureml-logs/55_batchai_stdout.txt': 'https://azuremlestorage9451e43f9.blob.core.windows.net/azureml/ExperimentRun/dcid.keras-mnist_1561473949_451ed77e/azureml-logs/55_batchai_stdout.txt?sv=2018-03-28&sr=b&sig=vxvLhpZDUJeRJ17FfrrEjGl7wK7SFuAlC8jsZxcYAr8%3D&st=2019-06-25T14%3A52%3A25Z&se=2019-06-25T23%3A02%3A25Z&sp=r',\n",
       "  'azureml-logs/55_batchai_stdout-job_prep.txt': 'https://azuremlestorage9451e43f9.blob.core.windows.net/azureml/ExperimentRun/dcid.keras-mnist_1561473949_451ed77e/azureml-logs/55_batchai_stdout-job_prep.txt?sv=2018-03-28&sr=b&sig=DPuTpc5ZTHcgXLr2wLz53xPEPB83LVwRNNGC6GXjf8A%3D&st=2019-06-25T14%3A52%3A25Z&se=2019-06-25T23%3A02%3A25Z&sp=r',\n",
       "  'logs/azureml/137_azureml.log': 'https://azuremlestorage9451e43f9.blob.core.windows.net/azureml/ExperimentRun/dcid.keras-mnist_1561473949_451ed77e/logs/azureml/137_azureml.log?sv=2018-03-28&sr=b&sig=o9DhAA4h2YepP96ycBAYw6uSlCZkPXM6XRqqz%2FE34e4%3D&st=2019-06-25T14%3A52%3A25Z&se=2019-06-25T23%3A02%3A25Z&sp=r',\n",
       "  'logs/azureml/azureml.log': 'https://azuremlestorage9451e43f9.blob.core.windows.net/azureml/ExperimentRun/dcid.keras-mnist_1561473949_451ed77e/logs/azureml/azureml.log?sv=2018-03-28&sr=b&sig=UB%2BBUVtSxiZ1H7aFVOvKXXdDwheeDD40noOSRIfb8ns%3D&st=2019-06-25T14%3A52%3A25Z&se=2019-06-25T23%3A02%3A25Z&sp=r'}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the outputs of the training script, it prints out the Keras version number. Please make a note of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Run object\n",
    "The Run object provides the interface to the run history -- both to the job and to the control plane (this notebook), and both while the job is running and after it has completed. It provides a number of interesting features for instance:\n",
    "* `run.get_details()`: Provides a rich set of properties of the run\n",
    "* `run.get_metrics()`: Provides a dictionary with all the metrics that were reported for the Run\n",
    "* `run.get_file_names()`: List all the files that were uploaded to the run history for this Run. This will include the `outputs` and `logs` folder, azureml-logs and other logs, as well as files that were explicitly uploaded to the run using `run.upload_file()`\n",
    "\n",
    "Below are some examples -- please run through them and inspect their output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runId': 'keras-mnist_1561473949_451ed77e',\n",
       " 'target': 'gpu-cluster',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2019-06-25T14:59:01.717853Z',\n",
       " 'endTimeUtc': '2019-06-25T15:02:23.08799Z',\n",
       " 'properties': {'azureml.runsource': 'experiment',\n",
       "  'AzureML.DerivedImageName': 'azureml/azureml_e639d7869712879dfdb1d61005d0d6e0',\n",
       "  'ContentSnapshotId': 'bcde896a-e0a8-4257-8aa0-1f3f89f4555e'},\n",
       " 'runDefinition': {'script': 'keras_mnist.py',\n",
       "  'arguments': ['--data-folder',\n",
       "   '$AZUREML_DATAREFERENCE_c236cf1297ba41378d4ce4d49deba0cc',\n",
       "   '--batch-size',\n",
       "   '50',\n",
       "   '--first-layer-neurons',\n",
       "   '300',\n",
       "   '--second-layer-neurons',\n",
       "   '100',\n",
       "   '--learning-rate',\n",
       "   '0.001'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'gpu-cluster',\n",
       "  'dataReferences': {'c236cf1297ba41378d4ce4d49deba0cc': {'dataStoreName': 'workspaceblobstore',\n",
       "    'mode': 'Mount',\n",
       "    'pathOnDataStore': 'mnist',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False}},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'Experiment keras-mnist Environment',\n",
       "   'version': 'Autosave_2019-06-25T14:45:53Z_0ff07d2c',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'name': 'project_environment',\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['keras',\n",
       "        'matplotlib',\n",
       "        'azureml-defaults',\n",
       "        'tensorflow-gpu==1.13.1',\n",
       "        'horovod==0.16.1']}],\n",
       "     'channels': ['conda-forge']},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE',\n",
       "    'NCCL_SOCKET_IFNAME': '^docker0'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base-gpu:intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04',\n",
       "    'enabled': True,\n",
       "    'sharedVolumes': True,\n",
       "    'gpuSupport': True,\n",
       "    'shmSize': '1g',\n",
       "    'arguments': [],\n",
       "    'baseImageRegistry': {'address': None,\n",
       "     'username': None,\n",
       "     'password': None}},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': False}},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'vmPriority': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None},\n",
       " 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://azuremlestorage9451e43f9.blob.core.windows.net/azureml/ExperimentRun/dcid.keras-mnist_1561473949_451ed77e/azureml-logs/20_image_build_log.txt?sv=2018-03-28&sr=b&sig=Feb3IYwCJsdkqGcUbgxI9expd%2B9Sb7FjiyW0Iuh6ySo%3D&st=2019-06-25T14%3A56%3A01Z&se=2019-06-25T23%3A06%3A01Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://azuremlestorage9451e43f9.blob.core.windows.net/azureml/ExperimentRun/dcid.keras-mnist_1561473949_451ed77e/azureml-logs/70_driver_log.txt?sv=2018-03-28&sr=b&sig=EugWR5D3LZrjQiwBJaBdwQBWLmmJDIn%2B6iR6dfFGWwI%3D&st=2019-06-25T14%3A56%3A01Z&se=2019-06-25T23%3A06%3A01Z&sp=r',\n",
       "  'azureml-logs/driver_log.txt': 'https://azuremlestorage9451e43f9.blob.core.windows.net/azureml/ExperimentRun/dcid.keras-mnist_1561473949_451ed77e/azureml-logs/driver_log.txt?sv=2018-03-28&sr=b&sig=6zZBoYkW13uQg98TLNa0MvR5FAUD06NqoSGdrLIk314%3D&st=2019-06-25T14%3A56%3A01Z&se=2019-06-25T23%3A06%3A01Z&sp=r',\n",
       "  'azureml-logs/55_batchai_stdout-job_post.txt': 'https://azuremlestorage9451e43f9.blob.core.windows.net/azureml/ExperimentRun/dcid.keras-mnist_1561473949_451ed77e/azureml-logs/55_batchai_stdout-job_post.txt?sv=2018-03-28&sr=b&sig=A%2BqNiace%2BvmzEP%2BYl2jZBKHMtxTDzFUw%2FJrYHIdizrk%3D&st=2019-06-25T14%3A56%3A01Z&se=2019-06-25T23%3A06%3A01Z&sp=r',\n",
       "  'azureml-logs/56_batchai_stderr.txt': 'https://azuremlestorage9451e43f9.blob.core.windows.net/azureml/ExperimentRun/dcid.keras-mnist_1561473949_451ed77e/azureml-logs/56_batchai_stderr.txt?sv=2018-03-28&sr=b&sig=E9fMu6UpIfPNZ1VA0GDvq8stap6Qa%2FOkvMKrEMSjndU%3D&st=2019-06-25T14%3A56%3A01Z&se=2019-06-25T23%3A06%3A01Z&sp=r',\n",
       "  'azureml-logs/55_batchai_execution.txt': 'https://azuremlestorage9451e43f9.blob.core.windows.net/azureml/ExperimentRun/dcid.keras-mnist_1561473949_451ed77e/azureml-logs/55_batchai_execution.txt?sv=2018-03-28&sr=b&sig=SlQsvweBVdwUDc7Z7tyEE50F3zbBp1AZf9i8GJ%2BPl0M%3D&st=2019-06-25T14%3A56%3A01Z&se=2019-06-25T23%3A06%3A01Z&sp=r',\n",
       "  'azureml-logs/55_batchai_stdout.txt': 'https://azuremlestorage9451e43f9.blob.core.windows.net/azureml/ExperimentRun/dcid.keras-mnist_1561473949_451ed77e/azureml-logs/55_batchai_stdout.txt?sv=2018-03-28&sr=b&sig=SNQj82OKG6H28wbdF9iAHLKWNRMu2XTLWcn42yy82Xo%3D&st=2019-06-25T14%3A56%3A01Z&se=2019-06-25T23%3A06%3A01Z&sp=r',\n",
       "  'azureml-logs/55_batchai_stdout-job_prep.txt': 'https://azuremlestorage9451e43f9.blob.core.windows.net/azureml/ExperimentRun/dcid.keras-mnist_1561473949_451ed77e/azureml-logs/55_batchai_stdout-job_prep.txt?sv=2018-03-28&sr=b&sig=v6yKIm5gPyCxNy2kyr43BA8B5hpH9VeqV6hG0ijSeJU%3D&st=2019-06-25T14%3A56%3A01Z&se=2019-06-25T23%3A06%3A01Z&sp=r',\n",
       "  'logs/azureml/137_azureml.log': 'https://azuremlestorage9451e43f9.blob.core.windows.net/azureml/ExperimentRun/dcid.keras-mnist_1561473949_451ed77e/logs/azureml/137_azureml.log?sv=2018-03-28&sr=b&sig=MW0c0M5alpxDQSsF3cTQXBplYEGNhGHUKWtGA6jfVMU%3D&st=2019-06-25T14%3A56%3A01Z&se=2019-06-25T23%3A06%3A01Z&sp=r',\n",
       "  'logs/azureml/azureml.log': 'https://azuremlestorage9451e43f9.blob.core.windows.net/azureml/ExperimentRun/dcid.keras-mnist_1561473949_451ed77e/logs/azureml/azureml.log?sv=2018-03-28&sr=b&sig=VeNmDeapgPzHiAZ0U4nwldmybsOYGEwkX55jsxHBrms%3D&st=2019-06-25T14%3A56%3A01Z&se=2019-06-25T23%3A06%3A01Z&sp=r'}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Loss': [0.21193540368539593,\n",
       "  0.08979386562573685,\n",
       "  0.0640791903809683,\n",
       "  0.04969040511659841,\n",
       "  0.03851924479506427,\n",
       "  0.034629579259246084,\n",
       "  0.026691853923315422,\n",
       "  0.022164999651270893,\n",
       "  0.019180537446129336,\n",
       "  0.016137909693583575,\n",
       "  0.014995283454052431,\n",
       "  0.01181835241087434,\n",
       "  0.01221864976328655,\n",
       "  0.01097686702258443,\n",
       "  0.009526684323577537,\n",
       "  0.008651913791873628,\n",
       "  0.008176027018272787,\n",
       "  0.006864741751473722,\n",
       "  0.006263888735279886,\n",
       "  0.005459982245078159],\n",
       " 'Accuracy': [0.9361833322482804,\n",
       "  0.9733833349247774,\n",
       "  0.9812166696290175,\n",
       "  0.9855166707932949,\n",
       "  0.9889000045756499,\n",
       "  0.9902500042319298,\n",
       "  0.9924000041683515,\n",
       "  0.9935333373149237,\n",
       "  0.9943833367029826,\n",
       "  0.995666669656833,\n",
       "  0.9959333363175392,\n",
       "  0.9969333358108997,\n",
       "  0.9967500025530657,\n",
       "  0.9969833355148633,\n",
       "  0.9974500020345052,\n",
       "  0.9974333353837331,\n",
       "  0.9980000015099844,\n",
       "  0.9982166680693626,\n",
       "  0.9985166678329309,\n",
       "  0.9985666677852472],\n",
       " 'Final test loss': 0.1386978552624188,\n",
       " 'Final test accuracy': 0.9824,\n",
       " 'Accuracy vs Loss': 'aml://artifactId/ExperimentRun/dcid.keras-mnist_1561473949_451ed77e/Accuracy vs Loss_1561474928.png'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Accuracy vs Loss_1561474928.png',\n",
       " 'azureml-logs/20_image_build_log.txt',\n",
       " 'azureml-logs/55_batchai_execution.txt',\n",
       " 'azureml-logs/55_batchai_stdout-job_post.txt',\n",
       " 'azureml-logs/55_batchai_stdout-job_prep.txt',\n",
       " 'azureml-logs/55_batchai_stdout.txt',\n",
       " 'azureml-logs/56_batchai_stderr.txt',\n",
       " 'azureml-logs/70_driver_log.txt',\n",
       " 'azureml-logs/driver_log.txt',\n",
       " 'logs/azureml/137_azureml.log',\n",
       " 'logs/azureml/azureml.log',\n",
       " 'outputs/model/model.h5',\n",
       " 'outputs/model/model.json']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_file_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the saved model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the training script, the Keras model is saved into two files, `model.json` and `model.h5`, in the `outputs/models` folder on the gpu-cluster AmlCompute node. Azure ML automatically uploaded anything written in the `./outputs` folder into run history file store. Subsequently, we can use the `run` object to download the model files. They are under the the `outputs/model` folder in the run history file store, and are downloaded into a local folder named `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from outputs/model/model.h5 to ./model/model.h5 ...\n",
      "Downloading from outputs/model/model.json to ./model/model.json ...\n"
     ]
    }
   ],
   "source": [
    "# create a model folder in the current directory\n",
    "os.makedirs('./model', exist_ok=True)\n",
    "\n",
    "for f in run.get_file_names():\n",
    "    if f.startswith('outputs/model'):\n",
    "        output_file_path = os.path.join('./model', f.split('/')[-1])\n",
    "        print('Downloading from {} to {} ...'.format(f, output_file_path))\n",
    "        run.download_file(name=f, output_file_path=output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on the test set\n",
    "Let's check the version of the local Keras. Make sure it matches with the version number printed out in the training script. Otherwise you might not be able to load the model properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras version: 2.2.4\n",
      "Tensorflow version: 1.14.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Keras version:\", keras.__version__)\n",
    "print(\"Tensorflow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the downloaded model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0625 16:27:02.328063 4565059008 deprecation_wrapper.py:119] From /Users/psfriso/anaconda3/envs/azure_ml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0625 16:27:02.357424 4565059008 deprecation_wrapper.py:119] From /Users/psfriso/anaconda3/envs/azure_ml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0625 16:27:02.425621 4565059008 deprecation_wrapper.py:119] From /Users/psfriso/anaconda3/envs/azure_ml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0625 16:27:02.426526 4565059008 deprecation_wrapper.py:119] From /Users/psfriso/anaconda3/envs/azure_ml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0625 16:27:02.426990 4565059008 deprecation_wrapper.py:119] From /Users/psfriso/anaconda3/envs/azure_ml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from disk.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('model/model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model/model.h5\")\n",
    "print(\"Model loaded from disk.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed test dataset to the persisted model to get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_data, one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = load_data('../data/test-images.gz', False) / 255.0\n",
    "y_test = load_data('../data/test-labels.gz', True).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels:  \t [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1]\n",
      "predictions:\t [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1]\n"
     ]
    }
   ],
   "source": [
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "y_test_ohe = one_hot_encode(y_test, 10)\n",
    "y_hat = np.argmax(loaded_model.predict(X_test), axis=1)\n",
    "\n",
    "# print the first 30 labels and predictions\n",
    "print('labels:  \\t', y_test[:30])\n",
    "print('predictions:\\t', y_hat[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the overall accuracy by comparing the predicted value against the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 0.9824\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on the test set:\", np.average(y_hat == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intelligent hyperparameter tuning\n",
    "We have trained the model with one set of hyperparameters, now let's how we can do hyperparameter tuning by launching multiple runs on the cluster. First let's define the parameter space using random sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, HyperDriveConfig, PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive import choice, loguniform\n",
    "\n",
    "ps = RandomParameterSampling(\n",
    "    {\n",
    "        '--batch-size': choice(25, 50, 100),\n",
    "        '--first-layer-neurons': choice(10, 50, 200, 300, 500),\n",
    "        '--second-layer-neurons': choice(10, 50, 200, 500),\n",
    "        '--learning-rate': loguniform(-6, -1)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create a new estimator without the above parameters since they will be passed in later by Hyperdrive configuration. Note we still need to keep the `data-folder` parameter since that's not a hyperparamter we will sweep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0625 16:40:16.795565 4565059008 estimator.py:1048] framework_version is not specified, defaulting to version 1.13.\n"
     ]
    }
   ],
   "source": [
    "est = TensorFlow(source_directory=script_folder,\n",
    "                 script_params={'--data-folder': ds.path('mnist').as_mount()},\n",
    "                 compute_target=compute_target,\n",
    "                 conda_packages=['keras', 'matplotlib'],\n",
    "                 entry_script='keras_mnist.py', \n",
    "                 use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define an early termnination policy. The `BanditPolicy` basically states to check the job every 2 iterations. If the primary metric (defined later) falls outside of the top 10% range, Azure ML terminate the job. This saves us from continuing to explore hyperparameters that don't show promise of helping reach our target metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to configure a run configuration object, and specify the primary metric `Accuracy` that's recorded in your training runs. If you go back to visit the training script, you will notice that this value is being logged after every epoch (a full batch set). We also want to tell the service that we are looking to maximizing this value. We also set the number of samples to 20, and maximal concurrent job to 4, which is the same as the number of nodes in our computer cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PrimaryMetricGoal.MAXIMIZE\n"
     ]
    }
   ],
   "source": [
    "print(PrimaryMetricGoal.MAXIMIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdc = HyperDriveConfig(estimator=est, \n",
    "                       hyperparameter_sampling=ps, \n",
    "                       policy=policy, \n",
    "                       primary_metric_name='Accuracy', \n",
    "                       primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n",
    "                       max_total_runs=20,\n",
    "                       max_concurrent_runs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's launch the hyperparameter tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdr = exp.submit(config=hdc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a run history widget to show the progress. Be patient as this might take a while to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "175fbf5919204af0a73164710f8c1dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RunDetails(hdr).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: keras-mnist_1561477492652\n",
      "Web View: https://mlworkspace.azure.ai/portal/subscriptions/79ec9c01-599f-4707-82f9-31b2d938f2e5/resourceGroups/pedro-test/providers/Microsoft.MachineLearningServices/workspaces/azure-ml-experiments/experiments/keras-mnist/runs/keras-mnist_1561477492652\n",
      "\n",
      "Streaming azureml-logs/hyperdrive.txt\n",
      "=====================================\n",
      "\n",
      "\"<START>[2019-06-25T15:44:53.111169][API][INFO]Experiment created<END>\\n\"\"<START>[2019-06-25T15:44:53.371738][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space<END>\\n\"\"<START>[2019-06-25T15:44:53.466013][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.<END>\\n\"<START>[2019-06-25T15:44:56.0296609Z][SCHEDULER][INFO]The execution environment is being prepared. Please be patient as it can take a few minutes.<END>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0625 17:08:11.550705 4565059008 connectionpool.py:665] Retrying (Retry(total=2, connect=3, read=2, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', OSError(\"(60, 'ETIMEDOUT')\",))': /azureml/ExperimentRun/dcid.keras-mnist_1561477492652/azureml-logs/hyperdrive.txt?sv=2018-03-28&sr=b&sig=tGfF8YF7%2FaRCAMRudLqfr3v3zh3Rp6BxJyAwgzjxAgY%3D&st=2019-06-25T15%3A57%3A52Z&se=2019-06-26T00%3A07%3A52Z&sp=r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: keras-mnist_1561477492652\n",
      "Web View: https://mlworkspace.azure.ai/portal/subscriptions/79ec9c01-599f-4707-82f9-31b2d938f2e5/resourceGroups/pedro-test/providers/Microsoft.MachineLearningServices/workspaces/azure-ml-experiments/experiments/keras-mnist/runs/keras-mnist_1561477492652\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'keras-mnist_1561477492652',\n",
       " 'target': 'gpu-cluster',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2019-06-25T15:44:52.983649Z',\n",
       " 'endTimeUtc': '2019-06-25T16:16:23.000Z',\n",
       " 'properties': {'primary_metric_config': '{\"name\": \"Accuracy\", \"goal\": \"maximize\"}',\n",
       "  'runTemplate': 'HyperDrive',\n",
       "  'azureml.runsource': 'hyperdrive',\n",
       "  'ContentSnapshotId': 'bcde896a-e0a8-4257-8aa0-1f3f89f4555e'},\n",
       " 'logFiles': {'azureml-logs/hyperdrive.txt': 'https://azuremlestorage9451e43f9.blob.core.windows.net/azureml/ExperimentRun/dcid.keras-mnist_1561477492652/azureml-logs/hyperdrive.txt?sv=2018-03-28&sr=b&sig=siqFFY8gA4rz%2F4USI9sW%2FgoFEE1E0PG019%2FHUv8RZ70%3D&st=2019-06-25T16%3A06%3A24Z&se=2019-06-26T00%3A16%3A24Z&sp=r'}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdr.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find and register best model\n",
    "When all the jobs finish, we can find out the one that has the highest accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['--data-folder', '$AZUREML_DATAREFERENCE_bee0b4637f1f47cda6b8c9f7be91c1b8', '--batch-size', '50', '--first-layer-neurons', '300', '--learning-rate', '0.00268786311136608', '--second-layer-neurons', '10']\n"
     ]
    }
   ],
   "source": [
    "best_run = hdr.get_best_run_by_primary_metric()\n",
    "print(best_run.get_details()['runDefinition']['arguments'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's list the model files uploaded during the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Accuracy vs Loss_1561479261.png', 'azureml-logs/55_batchai_execution.txt', 'azureml-logs/55_batchai_stdout-job_post.txt', 'azureml-logs/55_batchai_stdout-job_prep.txt', 'azureml-logs/55_batchai_stdout.txt', 'azureml-logs/70_driver_log.txt', 'azureml-logs/driver_log.txt', 'logs/azureml/138_azureml.log', 'logs/azureml/azureml.log', 'outputs/model/model.h5', 'outputs/model/model.json']\n"
     ]
    }
   ],
   "source": [
    "print(best_run.get_file_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then register the folder (and all files in it) as a model named `keras-dnn-mnist` under the workspace for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_run.register_model(model_name='keras-mlp-mnist', model_path='outputs/model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model in ACI\n",
    "Now we are ready to deploy the model as a web service running in Azure Container Instance [ACI](https://azure.microsoft.com/en-us/services/container-instances/). Azure Machine Learning accomplishes this by constructing a Docker image with the scoring logic and model baked in.\n",
    "### Create score.py\n",
    "First, we will create a scoring script that will be invoked by the web service call. \n",
    "\n",
    "* Note that the scoring script must have two required functions, `init()` and `run(input_data)`. \n",
    "  * In `init()` function, you typically load the model into a global object. This function is executed only once when the Docker container is started. \n",
    "  * In `run(input_data)` function, the model is used to predict a value based on the input data. The input and output to `run` typically use JSON as serialization and de-serialization format but you are not limited to that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from azureml.core.model import Model\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    \n",
    "    model_root = Model.get_model_path('keras-mlp-mnist')\n",
    "    # load json and create model\n",
    "    json_file = open(os.path.join(model_root, 'model.json'), 'r')\n",
    "    model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(model_json)\n",
    "    # load weights into new model\n",
    "    model.load_weights(os.path.join(model_root, \"model.h5\"))   \n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    \n",
    "def run(raw_data):\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    # make prediction\n",
    "    y_hat = np.argmax(model.predict(data), axis=1)\n",
    "    return y_hat.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create myenv.yml\n",
    "We also need to create an environment file so that Azure Machine Learning can install the necessary packages in the Docker image which are required by your scoring script. In this case, we need to specify conda packages `tensorflow` and `keras`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Conda environment specification. The dependencies defined in this file will\r\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\r\n",
      "\n",
      "# Details about the Conda environment file format:\r\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\r\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\r\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\r\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "  - azureml-defaults\n",
      "- tensorflow\n",
      "- keras\n",
      "- scikit-learn\n",
      "channels:\n",
      "- conda-forge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.runconfig import CondaDependencies\n",
    "\n",
    "cd = CondaDependencies.create()\n",
    "cd.add_conda_package('tensorflow')\n",
    "cd.add_conda_package('keras')\n",
    "cd.add_conda_package('scikit-learn')\n",
    "cd.save_to_file(base_directory='./', conda_file_path='myenv.yml')\n",
    "\n",
    "print(cd.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy to ACI\n",
    "We are almost ready to deploy. Create a deployment configuration and specify the number of CPUs and gigbyte of RAM needed for your ACI container. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               auth_enabled=True, # this flag generates API keys to secure access\n",
    "                                               memory_gb=1, \n",
    "                                               tags={'name':'mnist', 'framework': 'Keras'},\n",
    "                                               description='Keras MLP on MNIST')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deployment Process\n",
    "Now we can deploy. **This cell will run for about 7-8 minutes**. Behind the scene, it will do the following:\n",
    "1. **Build Docker image**  \n",
    "Build a Docker image using the scoring file (`score.py`), the environment file (`myenv.yml`), and the `model` object. \n",
    "2. **Register image**    \n",
    "Register that image under the workspace. \n",
    "3. **Ship to ACI**    \n",
    "And finally ship the image to the ACI infrastructure, start up a container in ACI using that image, and expose an HTTP endpoint to accept REST client calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "imgconfig = ContainerImage.image_configuration(execution_script=\"score.py\", \n",
    "                                               runtime=\"python\", \n",
    "                                               conda_file=\"myenv.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Running......................................................\n",
      "Succeeded\n",
      "Image creation operation finished for image keras-mnist-svc:1, operation \"Succeeded\"\n",
      "Creating service\n",
      "Running.\n",
      "Failed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0625 17:48:24.968159 4565059008 _azureml_exception.py:175] Service deployment polling reached non-successful terminal state, current service state: Transitioning\n",
      "Error:\n",
      "{\n",
      "  \"code\": \"RequestDisallowedByPolicy\",\n",
      "  \"statusCode\": 403,\n",
      "  \"message\": \"ACI Service request failed. Reason: Resource 'keras-mnist-svc' was disallowed by policy. Policy identifiers: '[{\\\"policyAssignment\\\":{\\\"name\\\":\\\"Mandatory\\\",\\\"id\\\":\\\"/providers/Microsoft.Management/managementGroups/f55b1f7d-7a7f-49e4-9b90-55218aad89f8/providers/Microsoft.Authorization/policyAssignments/9978978c349a4e128d18fe76\\\"},\\\"policyDefinition\\\":{\\\"name\\\":\\\"Allowed locations\\\",\\\"id\\\":\\\"/providers/Microsoft.Authorization/policyDefinitions/e56962a6-4747-49cd-b67b-bf8b01975c4c\\\"},\\\"policySetDefinition\\\":{\\\"name\\\":\\\"Mandatory\\\",\\\"id\\\":\\\"/providers/Microsoft.Management/managementgroups/f55b1f7d-7a7f-49e4-9b90-55218aad89f8/providers/Microsoft.Authorization/policySetDefinitions/Important\\\"}}]'..\"\n",
      "}\n",
      "\n",
      "E0625 17:48:24.969106 4565059008 _azureml_exception.py:175] Service deployment polling reached non-successful terminal state, current service state: Transitioning\n",
      "Error:\n",
      "{\n",
      "  \"code\": \"RequestDisallowedByPolicy\",\n",
      "  \"statusCode\": 403,\n",
      "  \"message\": \"ACI Service request failed. Reason: Resource 'keras-mnist-svc' was disallowed by policy. Policy identifiers: '[{\\\"policyAssignment\\\":{\\\"name\\\":\\\"Mandatory\\\",\\\"id\\\":\\\"/providers/Microsoft.Management/managementGroups/f55b1f7d-7a7f-49e4-9b90-55218aad89f8/providers/Microsoft.Authorization/policyAssignments/9978978c349a4e128d18fe76\\\"},\\\"policyDefinition\\\":{\\\"name\\\":\\\"Allowed locations\\\",\\\"id\\\":\\\"/providers/Microsoft.Authorization/policyDefinitions/e56962a6-4747-49cd-b67b-bf8b01975c4c\\\"},\\\"policySetDefinition\\\":{\\\"name\\\":\\\"Mandatory\\\",\\\"id\\\":\\\"/providers/Microsoft.Management/managementgroups/f55b1f7d-7a7f-49e4-9b90-55218aad89f8/providers/Microsoft.Authorization/policySetDefinitions/Important\\\"}}]'..\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "ename": "WebserviceException",
     "evalue": "Service deployment polling reached non-successful terminal state, current service state: Transitioning\nError:\n{\n  \"code\": \"RequestDisallowedByPolicy\",\n  \"statusCode\": 403,\n  \"message\": \"ACI Service request failed. Reason: Resource 'keras-mnist-svc' was disallowed by policy. Policy identifiers: '[{\\\"policyAssignment\\\":{\\\"name\\\":\\\"Mandatory\\\",\\\"id\\\":\\\"/providers/Microsoft.Management/managementGroups/f55b1f7d-7a7f-49e4-9b90-55218aad89f8/providers/Microsoft.Authorization/policyAssignments/9978978c349a4e128d18fe76\\\"},\\\"policyDefinition\\\":{\\\"name\\\":\\\"Allowed locations\\\",\\\"id\\\":\\\"/providers/Microsoft.Authorization/policyDefinitions/e56962a6-4747-49cd-b67b-bf8b01975c4c\\\"},\\\"policySetDefinition\\\":{\\\"name\\\":\\\"Mandatory\\\",\\\"id\\\":\\\"/providers/Microsoft.Management/managementgroups/f55b1f7d-7a7f-49e4-9b90-55218aad89f8/providers/Microsoft.Authorization/policySetDefinitions/Important\\\"}}]'..\"\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/azure_ml/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36mwait_for_deployment\u001b[0;34m(self, show_output)\u001b[0m\n\u001b[1;32m    465\u001b[0m                                           \u001b[0;34m'Error:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m                                           '{}'.format(self.state, error_response), logger=module_logger)\n\u001b[0m\u001b[1;32m    467\u001b[0m             print('{} service creation operation finished, operation \"{}\"'.format(self._webservice_type,\n",
      "\u001b[0;31mWebserviceException\u001b[0m: Service deployment polling reached non-successful terminal state, current service state: Transitioning\nError:\n{\n  \"code\": \"RequestDisallowedByPolicy\",\n  \"statusCode\": 403,\n  \"message\": \"ACI Service request failed. Reason: Resource 'keras-mnist-svc' was disallowed by policy. Policy identifiers: '[{\\\"policyAssignment\\\":{\\\"name\\\":\\\"Mandatory\\\",\\\"id\\\":\\\"/providers/Microsoft.Management/managementGroups/f55b1f7d-7a7f-49e4-9b90-55218aad89f8/providers/Microsoft.Authorization/policyAssignments/9978978c349a4e128d18fe76\\\"},\\\"policyDefinition\\\":{\\\"name\\\":\\\"Allowed locations\\\",\\\"id\\\":\\\"/providers/Microsoft.Authorization/policyDefinitions/e56962a6-4747-49cd-b67b-bf8b01975c4c\\\"},\\\"policySetDefinition\\\":{\\\"name\\\":\\\"Mandatory\\\",\\\"id\\\":\\\"/providers/Microsoft.Management/managementgroups/f55b1f7d-7a7f-49e4-9b90-55218aad89f8/providers/Microsoft.Authorization/policySetDefinitions/Important\\\"}}]'..\"\n}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/azure_ml/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36mwait_for_deployment\u001b[0;34m(self, show_output)\u001b[0m\n\u001b[1;32m    473\u001b[0m                                           'Current state is {}'.format(self.state), logger=module_logger)\n\u001b[1;32m    474\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mWebserviceException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodule_logger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wait_for_operation_to_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebserviceException\u001b[0m: Service deployment polling reached non-successful terminal state, current service state: Transitioning\nError:\n{\n  \"code\": \"RequestDisallowedByPolicy\",\n  \"statusCode\": 403,\n  \"message\": \"ACI Service request failed. Reason: Resource 'keras-mnist-svc' was disallowed by policy. Policy identifiers: '[{\\\"policyAssignment\\\":{\\\"name\\\":\\\"Mandatory\\\",\\\"id\\\":\\\"/providers/Microsoft.Management/managementGroups/f55b1f7d-7a7f-49e4-9b90-55218aad89f8/providers/Microsoft.Authorization/policyAssignments/9978978c349a4e128d18fe76\\\"},\\\"policyDefinition\\\":{\\\"name\\\":\\\"Allowed locations\\\",\\\"id\\\":\\\"/providers/Microsoft.Authorization/policyDefinitions/e56962a6-4747-49cd-b67b-bf8b01975c4c\\\"},\\\"policySetDefinition\\\":{\\\"name\\\":\\\"Mandatory\\\",\\\"id\\\":\\\"/providers/Microsoft.Management/managementgroups/f55b1f7d-7a7f-49e4-9b90-55218aad89f8/providers/Microsoft.Authorization/policySetDefinitions/Important\\\"}}]'..\"\n}"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "service = Webservice.deploy_from_model(workspace=ws,\n",
    "                                       name='keras-mnist-svc',\n",
    "                                       deployment_config=aciconfig,\n",
    "                                       models=[model],\n",
    "                                       image_config=imgconfig)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip: If something goes wrong with the deployment, the first thing to look at is the logs from the service by running the following command:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0625 17:48:25.284075 4565059008 _azureml_exception.py:175] Received bad response from Model Management Service:\n",
      "Response Code: 404\n",
      "Headers: {'Date': 'Tue, 25 Jun 2019 16:48:25 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Vary': 'Accept-Encoding', 'Request-Context': 'appId=cid-v1:6a27ce65-5555-41a3-85f7-b7a1ce31fd6b', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'x-ms-client-request-id': '5c9e90e8896c4fe5b8e167e4954fff7a', 'x-ms-client-session-id': '', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload', 'Content-Encoding': 'gzip'}\n",
      "Content: b'{\"code\":\"NotFound\",\"statusCode\":404,\"message\":\"The specified resource was not found\",\"details\":[{\"code\":\"ResourceNotFound\",\"message\":\"The Resource \\'Microsoft.ContainerInstance/containerGroups/keras-mnist-svc\\' under resource group \\'pedro-test\\' was not found.\"}]}'\n",
      "\n"
     ]
    },
    {
     "ename": "WebserviceException",
     "evalue": "Received bad response from Model Management Service:\nResponse Code: 404\nHeaders: {'Date': 'Tue, 25 Jun 2019 16:48:25 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Vary': 'Accept-Encoding', 'Request-Context': 'appId=cid-v1:6a27ce65-5555-41a3-85f7-b7a1ce31fd6b', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'x-ms-client-request-id': '5c9e90e8896c4fe5b8e167e4954fff7a', 'x-ms-client-session-id': '', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload', 'Content-Encoding': 'gzip'}\nContent: b'{\"code\":\"NotFound\",\"statusCode\":404,\"message\":\"The specified resource was not found\",\"details\":[{\"code\":\"ResourceNotFound\",\"message\":\"The Resource \\'Microsoft.ContainerInstance/containerGroups/keras-mnist-svc\\' under resource group \\'pedro-test\\' was not found.\"}]}'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-d9b3c3bf9972>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/azure_ml/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36mget_logs\u001b[0;34m(self, num_lines)\u001b[0m\n\u001b[1;32m    727\u001b[0m                                       \u001b[0;34m'Headers: {}\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                                       \u001b[0;34m'Content: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                                       logger=module_logger)\n\u001b[0m\u001b[1;32m    730\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebserviceException\u001b[0m: Received bad response from Model Management Service:\nResponse Code: 404\nHeaders: {'Date': 'Tue, 25 Jun 2019 16:48:25 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Vary': 'Accept-Encoding', 'Request-Context': 'appId=cid-v1:6a27ce65-5555-41a3-85f7-b7a1ce31fd6b', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'x-ms-client-request-id': '5c9e90e8896c4fe5b8e167e4954fff7a', 'x-ms-client-session-id': '', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload', 'Content-Encoding': 'gzip'}\nContent: b'{\"code\":\"NotFound\",\"statusCode\":404,\"message\":\"The specified resource was not found\",\"details\":[{\"code\":\"ResourceNotFound\",\"message\":\"The Resource \\'Microsoft.ContainerInstance/containerGroups/keras-mnist-svc\\' under resource group \\'pedro-test\\' was not found.\"}]}'"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the scoring web service endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the deployed model\n",
    "Let's test the deployed model. Pick 30 random samples from the test set, and send it to the web service hosted in ACI. Note here we are using the `run` API in the SDK to invoke the service. You can also make raw HTTP calls using any HTTP tool such as curl.\n",
    "\n",
    "After the invocation, we print the returned predictions and plot them along with the input images. Use red font color and inversed image (white on black) to highlight the misclassified samples. Note since the model accuracy is pretty high, you might have to run the below cell a few times before you can see a misclassified sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# find 30 random samples from test set\n",
    "n = 30\n",
    "sample_indices = np.random.permutation(X_test.shape[0])[0:n]\n",
    "\n",
    "test_samples = json.dumps({\"data\": X_test[sample_indices].tolist()})\n",
    "test_samples = bytes(test_samples, encoding='utf8')\n",
    "\n",
    "# predict using the deployed model\n",
    "result = service.run(input_data=test_samples)\n",
    "\n",
    "# compare actual value vs. the predicted values:\n",
    "i = 0\n",
    "plt.figure(figsize = (20, 1))\n",
    "\n",
    "for s in sample_indices:\n",
    "    plt.subplot(1, n, i + 1)\n",
    "    plt.axhline('')\n",
    "    plt.axvline('')\n",
    "    \n",
    "    # use different color for misclassified sample\n",
    "    font_color = 'red' if y_test[s] != result[i] else 'black'\n",
    "    clr_map = plt.cm.gray if y_test[s] != result[i] else plt.cm.Greys\n",
    "    \n",
    "    plt.text(x=10, y=-10, s=y_hat[s], fontsize=18, color=font_color)\n",
    "    plt.imshow(X_test[s].reshape(28, 28), cmap=clr_map)\n",
    "    \n",
    "    i = i + 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retreive the API keys used for accessing the HTTP endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retreive the API keys. two keys were generated.\n",
    "key1, Key2 = service.get_keys()\n",
    "print(key1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now send construct raw HTTP request and send to the service. Don't forget to add key to the HTTP header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# send a random row from the test set to score\n",
    "random_index = np.random.randint(0, len(X_test)-1)\n",
    "input_data = \"{\\\"data\\\": [\" + str(list(X_test[random_index])) + \"]}\"\n",
    "\n",
    "headers = {'Content-Type':'application/json', 'Authorization': 'Bearer ' + key1}\n",
    "\n",
    "resp = requests.post(service.scoring_uri, input_data, headers=headers)\n",
    "\n",
    "print(\"POST to url\", service.scoring_uri)\n",
    "#print(\"input data:\", input_data)\n",
    "print(\"label:\", y_test[random_index])\n",
    "print(\"prediction:\", resp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the workspace after the web service was deployed. You should see \n",
    "* a registered model named 'keras-mlp-mnist' and with the id 'model:1'\n",
    "* an image called 'keras-mnist-svc' and with a docker image location pointing to your workspace's Azure Container Registry (ACR)  \n",
    "* a webservice called 'keras-mnist-svc' with some scoring URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ws.models\n",
    "for name, model in models.items():\n",
    "    print(\"Model: {}, ID: {}\".format(name, model.id))\n",
    "    \n",
    "images = ws.images\n",
    "for name, image in images.items():\n",
    "    print(\"Image: {}, location: {}\".format(name, image.image_location))\n",
    "    \n",
    "webservices = ws.webservices\n",
    "for name, webservice in webservices.items():\n",
    "    print(\"Webservice: {}, scoring URI: {}\".format(name, webservice.scoring_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "You can delete the ACI deployment with a simple delete API call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "maxluk"
   }
  ],
  "kernelspec": {
   "display_name": "azure_ml",
   "language": "python",
   "name": "azure_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "msauthor": "maxluk"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
